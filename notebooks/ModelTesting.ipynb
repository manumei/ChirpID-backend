{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b62d0e",
   "metadata": {},
   "source": [
    "Please read, complete and clean up ModelTesting.ipynb. Its purpose is to run the test set inference on all the final_cnn_models and final_fcnn_models. I then want to plot 1 main graph, a columns graph displaying the F1 Score for each of the six models, with an edge coloring of the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9d199",
   "metadata": {},
   "source": [
    "# Model Testing on Test Set\n",
    "\n",
    "Runs inference on the test audio files and displays the final metrics of the chosen models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e92077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import our custom modules\n",
    "from utils.inference import perform_audio_inference, perform_audio_inference_fcnn\n",
    "from utils.models import BirdCNN\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf089cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "NUM_CLASSES = 33\n",
    "MODEL_WEIGHTS_PATH = os.path.join('..', 'models', 'bird_cnn.pth')\n",
    "TEST_AUDIO_DIR = os.path.join('..', 'database', 'audio', 'test')\n",
    "TEST_METADATA_PATH = os.path.join('..', 'database', 'meta', 'test_data.csv')\n",
    "\n",
    "# Load test metadata\n",
    "print(\"Loading test metadata...\")\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)\n",
    "print(f\"✓ Loaded {len(test_df)} test samples\")\n",
    "print(f\"✓ Columns: {list(test_df.columns)}\")\n",
    "print(f\"✓ Classes represented: {test_df['class_id'].nunique()}\")\n",
    "print(f\"✓ Class distribution:\")\n",
    "print(test_df['class_id'].value_counts().sort_index())\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Verify audio files exist and create file mapping\n",
    "print(\"Verifying audio files...\")\n",
    "audio_files = os.listdir(TEST_AUDIO_DIR)\n",
    "print(f\"✓ Found {len(audio_files)} audio files in test directory\")\n",
    "\n",
    "# Create mapping of filename to full path and check if all metadata files exist\n",
    "test_files = []\n",
    "missing_files = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    audio_path = os.path.join(TEST_AUDIO_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(audio_path):\n",
    "        test_files.append({\n",
    "            'filename': filename,\n",
    "            'path': audio_path,\n",
    "            'class_id': row['class_id']\n",
    "        })\n",
    "    else:\n",
    "        missing_files.append(filename)\n",
    "\n",
    "print(f\"✓ Valid files: {len(test_files)}\")\n",
    "if missing_files:\n",
    "    print(f\"⚠ Missing files: {len(missing_files)}\")\n",
    "    print(f\"  First few missing: {missing_files[:5]}\")\n",
    "else:\n",
    "    print(\"✓ All metadata files found in audio directory\")\n",
    "\n",
    "print(f\"\\nReady to test on {len(test_files)} audio files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ef4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Configurations to try\n",
    "from utils.final_models import BirdCNN_v5, BirdCNN_v5c, BirdCNN_v7, BirdCNN_v7e\n",
    "from utils.fcnn_models import ...\n",
    "\n",
    "v5_path = ...\n",
    "\n",
    "# Final Models ({'name': (Model Class, PTH Path)})\n",
    "final_cnn_models = {\n",
    "    \n",
    "}\n",
    "\n",
    "final_fcnn_models = {\n",
    "    \n",
    "}\n",
    "\n",
    "# Storage for results\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "all_true_labels = []\n",
    "failed_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each test file, CNNs\n",
    "for i, file_info in enumerate(tqdm(test_files, desc=\"Processing audio files\")):\n",
    "    try:\n",
    "        # Perform inference\n",
    "        probabilities = perform_audio_inference(\n",
    "            audio_path=file_info['path'],\n",
    "            model_class=BirdCNN,\n",
    "            model_weights_path=MODEL_WEIGHTS_PATH,\n",
    "            reduce_noise=False\n",
    "        )\n",
    "        \n",
    "        # Get predicted class (argmax of probabilities)\n",
    "        predicted_class = np.argmax(probabilities)\n",
    "        \n",
    "        # Store results\n",
    "        all_probabilities.append(probabilities)\n",
    "        all_predictions.append(predicted_class)\n",
    "        all_true_labels.append(file_info['class_id'])\n",
    "        \n",
    "        # Progress update every 50 files\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(test_files)} files\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_info['filename']}: {str(e)}\")\n",
    "        failed_files.append(file_info['filename'])\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Inference completed!\")\n",
    "print(f\"✓ Successfully processed: {len(all_predictions)} files\")\n",
    "print(f\"✓ Failed files: {len(failed_files)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"Failed files: {failed_files[:5]}{'...' if len(failed_files) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ca4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each test file, FCNNs\n",
    "for i, file_info in enumerate(tqdm(test_files, desc=\"Processing audio files\")):\n",
    "    try:\n",
    "        # Perform inference\n",
    "        probabilities = perform_audio_inference_fcnn(\n",
    "            audio_path=file_info['path'],\n",
    "            model_class=BirdCNN,\n",
    "            model_weights_path=MODEL_WEIGHTS_PATH,\n",
    "            reduce_noise=False\n",
    "        )\n",
    "        \n",
    "        # Get predicted class (argmax of probabilities)\n",
    "        predicted_class = np.argmax(probabilities)\n",
    "        \n",
    "        # Store results\n",
    "        all_probabilities.append(probabilities)\n",
    "        all_predictions.append(predicted_class)\n",
    "        all_true_labels.append(file_info['class_id'])\n",
    "        \n",
    "        # Progress update every 50 files\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(test_files)} files\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_info['filename']}: {str(e)}\")\n",
    "        failed_files.append(file_info['filename'])\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Inference completed!\")\n",
    "print(f\"✓ Successfully processed: {len(all_predictions)} files\")\n",
    "print(f\"✓ Failed files: {len(failed_files)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"Failed files: {failed_files[:5]}{'...' if len(failed_files) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a198a35",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037cca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the F1 columns graph here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
