{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - running on CPU (will be slow)\")\n",
    "\n",
    "from utils import fcnn_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d20d1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11fe0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path: str) -> Tuple[np.ndarray, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Reads the CSV with all the training data: grayscale log-mel spectrogram pixels, label and author of each sample\n",
    "    And extracts them respectively, resizing the features to fit the CNN input shape (channel, height, width).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing training data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.array, np.array]: Returns features, labels, and authors from the CSV file. Features shape is (N x 70,112),\n",
    "        while labels and authors are 1D arrays of size N, where N is the number of samples.\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "    print(f\"Number of authors: {df['author'].nunique()}\")\n",
    "\n",
    "    # Extract labels, authors, and features\n",
    "    labels = df['label'].values.astype(np.int64)\n",
    "    authors = df['author'].values\n",
    "    features = df.drop(columns=['label', 'author']).values.astype(np.float32)\n",
    "    print(f\"Features shape before reshape: {features.shape} (should be N x 70112!)\")\n",
    "\n",
    "    # Convert to 0-1 range\n",
    "    features /= 255.0\n",
    "\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Authors shape:\", authors.shape)\n",
    "    print(\"Unique classes:\", len(np.unique(labels)))\n",
    "    print(\"Unique authors:\", len(np.unique(authors)))\n",
    "\n",
    "    # No need for df variable after extracting features, release memory\n",
    "    del df\n",
    "\n",
    "    return features, labels, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd89286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2987, 70114)\n",
      "Number of classes: 33\n",
      "Number of authors: 106\n",
      "Features shape before reshape: (2987, 70112) (should be N x 70112!)\n",
      "Features shape: (2987, 70112)\n",
      "Labels shape: (2987,)\n",
      "Authors shape: (2987,)\n",
      "Unique classes: 33\n",
      "Unique authors: 106\n",
      "Features shape before reshape: (2987, 70112) (should be N x 70112!)\n",
      "Features shape: (2987, 70112)\n",
      "Labels shape: (2987,)\n",
      "Authors shape: (2987,)\n",
      "Unique classes: 33\n",
      "Unique authors: 106\n"
     ]
    }
   ],
   "source": [
    "# Keep the old CSV-based loading for compatibility (uncomment if needed)\n",
    "train_data_path = os.path.join('..', 'database', 'meta', 'final', 'train_data.csv')\n",
    "features, labels, authors = load_csv_data(train_data_path)\n",
    "\n",
    "# Display class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique_labels, counts, alpha=0.7)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xticks(unique_labels)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average samples per class: {len(labels) / len(unique_labels):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ec270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2330 samples\n",
      "Validation set: 657 samples\n",
      "Split quality score: 0.26713002574246597\n",
      "\n",
      "üìä SINGLE SPLIT STATISTICS\n",
      "----------------------------------------\n",
      "Random seed: 245323\n",
      "Train samples: 2330\n",
      "Validation samples: 657\n",
      "Split ratio: 78.00% - 22.00%\n",
      "Quality score: 0.2671\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Split with a set seed, las que ya encontre arriba, para tardar menos\n",
    "from utils.split import get_set_seed_indices, display_split_statistics\n",
    "seed_single = 245323 # Quality: 0.2671\n",
    "\n",
    "train_indices, val_indices, best_score, seed = get_set_seed_indices(\n",
    "    features=features,\n",
    "    labels=labels, \n",
    "    authors=authors,\n",
    "    test_size=0.2,\n",
    "    seed=seed_single)\n",
    "\n",
    "# Extract train and validation data using indices\n",
    "trFeatures = features[train_indices]\n",
    "trLabels = labels[train_indices]\n",
    "trAuthors = authors[train_indices]\n",
    "\n",
    "vFeatures = features[val_indices]\n",
    "vLabels = labels[val_indices]\n",
    "vAuthors = authors[val_indices]\n",
    "\n",
    "print(f\"Training set: {trFeatures.shape[0]} samples\")\n",
    "print(f\"Validation set: {vFeatures.shape[0]} samples\")\n",
    "print(f\"Split quality score: {best_score}\")\n",
    "\n",
    "display_split_statistics((train_indices, val_indices, best_score, seed), \"single\")\n",
    "\n",
    "# Convert labels to one-hot encoding for BirdFCNN_v0 model\n",
    "num_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc110101",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19444a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fcnn_models import (\n",
    "    ...\n",
    ")\n",
    "from utils.metrics import plot_full_metrics\n",
    "import time\n",
    "import torch\n",
    "\n",
    "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "\n",
    "# Final FCNN Models - Select the best performing models from different categories\n",
    "final_models = {\n",
    "    'fcnn1': BirdFCNN_v0,  # Baseline model with SGD\n",
    "    'fcnn2': BirdFCNN_v1,  # Residual-inspired with skip connections\n",
    "}\n",
    "\n",
    "# Initialize results database for all model combinations\n",
    "building_results = {}\n",
    "class_num = num_classes\n",
    "\n",
    "print(f\"Ready to train {len(final_models)} FCNN models\")\n",
    "print(\"Selected models:\")\n",
    "for key, model_class in final_models.items():\n",
    "    print(f\"  {key}: {model_class.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cca091",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL FCNN MODELS TRAINING ===\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING FINAL FCNN MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_key, model_class in final_models.items():\n",
    "    try:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {model_key}: {model_class.__name__}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize model\n",
    "        model = model_class(num_classes=class_num, input_dim=trFeatures.shape[1])\n",
    "        \n",
    "        # Train model - each model handles its own configuration internally\n",
    "        result = model.train_model(\n",
    "            trainX=trFeatures,\n",
    "            trainY=trLabels,\n",
    "            valX=vFeatures,\n",
    "            valY=vLabels\n",
    "        )\n",
    "        \n",
    "        # Store result\n",
    "        building_results[model_key] = {\n",
    "            'status': 'success',\n",
    "            'result': result,\n",
    "            'training_time': time.time() - start_time,\n",
    "            'model_class': model_class,\n",
    "            'model': model  # Store the trained model\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_key} completed successfully!\")\n",
    "        print(f\"   Model: {model_class.__name__}\")\n",
    "        print(f\"   Best Val Acc: {result.get('best_val_acc', 0):.4f}\")\n",
    "        print(f\"   Best Val F1: {result.get('best_val_f1', 0):.4f}\")\n",
    "        print(f\"   Training time: {building_results[model_key]['training_time']:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {model_key} failed: {str(e)}\")\n",
    "        building_results[model_key] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e),\n",
    "            'model_class': model_class\n",
    "        }\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL FCNN MODELS TRAINING COMPLETED\")\n",
    "successful_models = sum(1 for result in building_results.values() if result['status'] == 'success')\n",
    "print(f\"Successful models: {successful_models}/{len(final_models)}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results plotting - Training metrics for all successful models\n",
    "print(\"=\"*80)\n",
    "print(\"PLOTTING TRAINING METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Plot training metrics for all successful models\n",
    "successful_results = []\n",
    "for model_key, data in building_results.items():\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        try:\n",
    "            # Use plot_full_metrics with history and confusion matrix\n",
    "            plot_full_metrics(\n",
    "                title=f\"{model_key} - {data['model_class'].__name__}\",\n",
    "                history=result['history'],\n",
    "                confusion_matrix=result.get('confusion_matrix', None)\n",
    "            )\n",
    "            successful_results.append((model_key, result))\n",
    "            print(f\"‚úÖ Plotted metrics for {model_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to plot {model_key}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully plotted metrics for {len(successful_results)} FCNN models\")\n",
    "\n",
    "# Create comprehensive results table\n",
    "print(\"=\"*80)\n",
    "print(\"BUILDING RESULTS TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "table_data = []\n",
    "for model_key, data in building_results.items():\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        \n",
    "        table_data.append({\n",
    "            'model': model_key,\n",
    "            'architecture': data['model_class'].__name__,\n",
    "            'best_val_acc': result.get('best_val_acc', 0),\n",
    "            'best_val_f1': result.get('best_val_f1', 0),\n",
    "            'training_time': data.get('training_time', 0)\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by best_val_f1 (descending)\n",
    "if table_data:\n",
    "    results_table = pd.DataFrame(table_data)\n",
    "    results_table = results_table.sort_values('best_val_f1', ascending=False)\n",
    "\n",
    "    print(\"FCNN MODEL RESULTS TABLE (sorted by Best Val F1)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(results_table.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total successful runs: {len(results_table)}\")\n",
    "    print(f\"Best F1 score: {results_table['best_val_f1'].max():.4f} ({results_table.loc[results_table['best_val_f1'].idxmax(), 'model']})\")\n",
    "    print(f\"Best accuracy: {results_table['best_val_acc'].max():.4f} ({results_table.loc[results_table['best_val_acc'].idxmax(), 'model']})\")\n",
    "    print(f\"Average F1 score: {results_table['best_val_f1'].mean():.4f}\")\n",
    "    print(f\"Average accuracy: {results_table['best_val_acc'].mean():.4f}\")\n",
    "    print(f\"Total training time: {results_table['training_time'].sum()/60:.1f} minutes\")\n",
    "    \n",
    "    # Top models by F1\n",
    "    print(f\"\\nTOP FCNN MODELS BY F1 SCORE:\")\n",
    "    top_models = results_table[['model', 'architecture', 'best_val_f1', 'best_val_acc']]\n",
    "    print(top_models.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "else:\n",
    "    print(\"No successful results found to display.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc990c",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90086bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained FCNN models to .pth files\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING FINAL FCNN MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models_dir = os.path.join('..', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "saved_models = 0\n",
    "for model_key, data in building_results.items():\n",
    "    if data['status'] == 'success' and 'model' in data:\n",
    "        try:\n",
    "            # Get the trained model from results\n",
    "            model = data['model']\n",
    "            \n",
    "            # Save the complete model (architecture + weights)\n",
    "            model_path = os.path.join(models_dir, f'{model_key.lower()}.pth')\n",
    "            torch.save(model, model_path)\n",
    "            \n",
    "            print(f\"‚úÖ Saved {model_key} to {model_path}\")\n",
    "            saved_models += 1\n",
    "            \n",
    "            # Also save just the state dict as backup\n",
    "            state_dict_path = os.path.join(models_dir, f'{model_key.lower()}_state_dict.pth')\n",
    "            torch.save(model.state_dict(), state_dict_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to save {model_key}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FCNN MODEL SAVING COMPLETED\")\n",
    "print(f\"Successfully saved {saved_models} out of {len([k for k, v in building_results.items() if v['status'] == 'success'])} trained models\")\n",
    "print(f\"Models saved to: {models_dir}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Display saved model information\n",
    "print(f\"\\nSAVED FCNN MODEL FILES:\")\n",
    "for model_key in building_results.keys():\n",
    "    if building_results[model_key]['status'] == 'success':\n",
    "        model_path = os.path.join(models_dir, f'{model_key.lower()}.pth')\n",
    "        if os.path.exists(model_path):\n",
    "            file_size = os.path.getsize(model_path) / (1024*1024)  # Size in MB\n",
    "            print(f\"  {model_key.lower()}.pth ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nTo load a FCNN model later, use:\")\n",
    "print(f\"model = torch.load('path/to/model.pth', weights_only=False)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
