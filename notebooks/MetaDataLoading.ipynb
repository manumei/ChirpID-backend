{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e95f834",
   "metadata": {},
   "source": [
    "Este agarra el CSV de todas las especies, y carga los CSVs recortados para procesar y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c241d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Selection\n",
    "\n",
    "MIN_LAT = -57.0 # decrease for more samples & species\n",
    "MAX_LAT = -15.0 # increase for more samples & species\n",
    "\n",
    "MIN_LON = -77.0 # decrease for more samples & species\n",
    "MAX_LON = -48.0 # increase for more samples & species\n",
    "\n",
    "SAMPLES_CUTOFF = 18 # decrease for more species\n",
    "SEGMENTS_CUTOFF = 72 # decrease for more species\n",
    "MIN_RATING_CUTOFF = 1 # decrease for more samples\n",
    "MIN_AUTHORS_CUTOFF = 9 # decrease for more species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82531a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "latin_america_bounds = {\n",
    "    \"lat\": (MIN_LAT, MAX_LAT),\n",
    "    \"lon\": (MIN_LON, MAX_LON)\n",
    "}\n",
    "\n",
    "df = pd.read_csv(os.path.join('..', 'database', 'train_metadata.csv'))\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "df = df[df['filename'].notna() & (df['filename'] != '')]\n",
    "df = df[~(df['scientific_name'].isna() & df['common_name'].isna())]\n",
    "print(f\"DataFrame shape after 'cuts': {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664782f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_region(lat, lon):\n",
    "    return (latin_america_bounds['lat'][0] <= lat <= latin_america_bounds['lat'][1] and\n",
    "            latin_america_bounds['lon'][0] <= lon <= latin_america_bounds['lon'][1])\n",
    "\n",
    "df['region'] = df.apply(lambda row: 'Latin America' if in_region(row['latitude'], row['longitude']) else None, axis=1)\n",
    "region_df = df[df['region'].notna()][['primary_label', 'latitude', 'longitude', 'scientific_name', 'common_name', 'region', 'filename', 'author']]\n",
    "\n",
    "# Add sample count per species\n",
    "species_counts = region_df['scientific_name'].value_counts().to_dict()\n",
    "region_df['amount_of_samples'] = region_df['scientific_name'].map(species_counts)\n",
    "\n",
    "# Drop rows where 'author' is NaN\n",
    "region_df = region_df.dropna(subset=['author'])\n",
    "\n",
    "# Create and apply label encoding to 'author' column\n",
    "author_encoder = LabelEncoder()\n",
    "region_df['author'] = author_encoder.fit_transform(region_df['author'])\n",
    "\n",
    "rated_df = region_df[df.loc[region_df.index, 'rating'] >= MIN_RATING_CUTOFF]\n",
    "rated_species_counts = rated_df['scientific_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rated_df is your DataFrame and contains 'primary_label' and 'filename' columns\n",
    "segment_sec = 5.0\n",
    "sr = 32000\n",
    "samples_per_segment = int(sr * segment_sec)\n",
    "frame_len = 2048\n",
    "hoplen = 512\n",
    "THRESH = 0.75\n",
    "\n",
    "usable_segments = []\n",
    "\n",
    "for _, row in rated_df.iterrows():\n",
    "    primary_label = row['primary_label']\n",
    "    filename = row['filename']\n",
    "    audio_path = os.path.join('../data/birdclef-2021/train_short_audio', primary_label, filename)\n",
    "\n",
    "    try:\n",
    "        y, srate = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {audio_path}: {e}\")\n",
    "        usable_segments.append(0)\n",
    "        continue\n",
    "\n",
    "    rms = librosa.feature.rms(y=y, frame_length=frame_len, hop_length=hoplen)[0]\n",
    "    threshold = THRESH * np.mean(rms)\n",
    "    count = 0\n",
    "\n",
    "    for start in range(0, len(y) - samples_per_segment + 1, samples_per_segment):\n",
    "        segment = y[start:start + samples_per_segment]\n",
    "        seg_rms = np.mean(librosa.feature.rms(y=segment)[0])\n",
    "        if seg_rms < threshold:\n",
    "            continue\n",
    "        count += 1\n",
    "\n",
    "    usable_segments.append(count)\n",
    "\n",
    "segs_df = rated_df.copy()\n",
    "segs_df['usable_segments'] = usable_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddab377",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_sample_counts = segs_df['scientific_name'].value_counts()\n",
    "species_segment_counts = segs_df.groupby('scientific_name')['usable_segments'].sum()\n",
    "\n",
    "species_to_keep = [\n",
    "    species for species in species_sample_counts.index\n",
    "    if species_sample_counts[species] >= SAMPLES_CUTOFF and species_segment_counts[species] >= SEGMENTS_CUTOFF\n",
    "]\n",
    "\n",
    "minsmps_df = segs_df[segs_df['scientific_name'].isin(species_to_keep)].copy()\n",
    "summary_table = minsmps_df.groupby('scientific_name').agg(\n",
    "    samples_count=('scientific_name', 'count'),\n",
    "    unique_segments_count=('usable_segments', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by unique_segments_count ascending\n",
    "summary_table = summary_table.sort_values('unique_segments_count', ascending=True)\n",
    "\n",
    "# Pretty print the table\n",
    "print(tabulate(summary_table, headers='keys', tablefmt='github', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab594b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author counts per species\n",
    "author_counts_per_species = minsmps_df.groupby('scientific_name')['author'].nunique()\n",
    "\n",
    "# Find species with less than 2 unique authors\n",
    "species_with_few_author = author_counts_per_species[author_counts_per_species < MIN_AUTHORS_CUTOFF]\n",
    "\n",
    "print(f\"Species with less than {MIN_AUTHORS_CUTOFF} unique authors ({len(species_with_few_author)} species):\")\n",
    "print(\"=\" * 60)\n",
    "for species, author_count in species_with_few_author.items():\n",
    "    print(f\"{species}: {author_count} author(s)\")\n",
    "\n",
    "# Filter out species with less than 2 unique authors\n",
    "species_to_keep_multiauthor = author_counts_per_species[author_counts_per_species >= MIN_AUTHORS_CUTOFF].index\n",
    "authors_df = minsmps_df[minsmps_df['scientific_name'].isin(species_to_keep_multiauthor)]\n",
    "\n",
    "print(f\"\\nAfter filtering species with less than {MIN_AUTHORS_CUTOFF} unique authors:\")\n",
    "print(f\"Remaining samples: {len(authors_df)}\")\n",
    "print(f\"Remaining species: {authors_df['scientific_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Class IDs for training\n",
    "final_df = authors_df[['primary_label', 'scientific_name', 'common_name', 'filename', 'author', 'usable_segments']].copy()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "final_df['class_id'] = le.fit_transform(final_df['scientific_name'])\n",
    "\n",
    "# Save species to CSV\n",
    "final_df.to_csv(os.path.join('..', 'database', 'meta', 'final_species.csv'), index=False)\n",
    "\n",
    "# Build mapping with class_id, scientific_name, common_name\n",
    "mapping_df = final_df[['class_id', 'scientific_name', 'common_name']].drop_duplicates().sort_values('class_id')\n",
    "mapping_df.to_csv(os.path.join('..', 'database', 'meta', 'class_mapping.csv'), index=False)\n",
    "\n",
    "print(f\"Final DataFrame shape: {final_df.shape}\")\n",
    "print(f\"Final number of samples: {len(final_df)}\")\n",
    "print(f\"Final number of usable segments: {final_df['usable_segments'].sum()}\")\n",
    "print(f\"Final number of species: {final_df['scientific_name'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
