{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c241d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Selection\n",
    "\n",
    "MIN_LAT = -57.0 # decrease for more samples & species\n",
    "MAX_LAT = -15.0 # increase for more samples & species\n",
    "\n",
    "MIN_LON = -77.0 # decrease for more samples & species\n",
    "MAX_LON = -48.0 # increase for more samples & species\n",
    "\n",
    "SAMPLES_CUTOFF = 18 # decrease for more species\n",
    "SEGMENTS_CUTOFF = 72 # decrease for more species\n",
    "MIN_RATING_CUTOFF = 1 # decrease for more samples\n",
    "MIN_AUTHORS_CUTOFF = 9 # decrease for more species\n",
    "\n",
    "SEG_LENGTH = 5.0 # seconds\n",
    "THRESH = 0.75 # decrease for more species\n",
    "CUT_TYPE = 'rms' # 'rms', 'peaks', 'entropy', 'filter', 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils.data_extraction import (\n",
    "    get_rmsThreshold, \n",
    "    get_peakThreshold, \n",
    "    get_spectralThreshold, \n",
    "    get_bandpassThreshold,\n",
    "    segment_has_energy_peaks,\n",
    "    segment_has_spectral_complexity,\n",
    "    segment_has_bandpass_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664782f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (62874, 8)\n",
      "DataFrame shape after cuts: (1962, 9)\n"
     ]
    }
   ],
   "source": [
    "# Add Regional Bounds\n",
    "latin_america_bounds = {\n",
    "    \"lat\": (MIN_LAT, MAX_LAT),\n",
    "    \"lon\": (MIN_LON, MAX_LON)\n",
    "}\n",
    "\n",
    "df = pd.read_csv(os.path.join('..', 'database', 'train_metadata.csv'))\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "df = df[df['filename'].notna() & (df['filename'] != '')]\n",
    "df = df[~(df['scientific_name'].isna() & df['common_name'].isna())]\n",
    "\n",
    "def in_region(lat, lon):\n",
    "    return (latin_america_bounds['lat'][0] <= lat <= latin_america_bounds['lat'][1] and\n",
    "            latin_america_bounds['lon'][0] <= lon <= latin_america_bounds['lon'][1])\n",
    "\n",
    "df['region'] = df.apply(lambda row: 'Latin America' if in_region(row['latitude'], row['longitude']) else None, axis=1)\n",
    "region_df = df[df['region'].notna()][['primary_label', 'latitude', 'longitude', 'scientific_name', 'common_name', 'region', 'filename', 'author']]\n",
    "\n",
    "# Add sample count per species\n",
    "species_counts = region_df['scientific_name'].value_counts().to_dict()\n",
    "region_df['amount_of_samples'] = region_df['scientific_name'].map(species_counts)\n",
    "\n",
    "# Drop rows where 'author' is NaN\n",
    "region_df = region_df.dropna(subset=['author'])\n",
    "\n",
    "# Create and apply label encoding to 'author' column\n",
    "author_encoder = LabelEncoder()\n",
    "region_df['author'] = author_encoder.fit_transform(region_df['author'])\n",
    "\n",
    "rated_df = region_df[df.loc[region_df.index, 'rating'] >= MIN_RATING_CUTOFF]\n",
    "rated_species_counts = rated_df['scientific_name'].value_counts()\n",
    "\n",
    "print(f\"DataFrame shape after cuts: {rated_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a3800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rated_df is your DataFrame and contains 'primary_label' and 'filename' columns\n",
    "sr = 32000\n",
    "samples_per_segment = int(sr * SEG_LENGTH)\n",
    "frame_len = 2048\n",
    "hoplen = 512\n",
    "\n",
    "usable_segments = []\n",
    "\n",
    "for _, row in rated_df.iterrows():\n",
    "    primary_label = row['primary_label']\n",
    "    filename = row['filename']\n",
    "    audio_path = os.path.join('../data/birdclef-2021/train_short_audio', primary_label, filename)\n",
    "\n",
    "    try:\n",
    "        y, srate = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {audio_path}: {e}\")\n",
    "        usable_segments.append(0)\n",
    "        continue\n",
    "\n",
    "    # Calculate threshold based on the chosen CUT_TYPE\n",
    "    if CUT_TYPE == 'rms':\n",
    "        threshold = get_rmsThreshold(y, frame_len, hoplen, thresh_factor=THRESH)\n",
    "    elif CUT_TYPE == 'peaks':\n",
    "        threshold = get_peakThreshold(y, frame_len, hoplen, thresh_factor=THRESH)\n",
    "    elif CUT_TYPE == 'entropy':\n",
    "        threshold = get_spectralThreshold(y, sr, frame_len, hoplen, thresh_factor=THRESH)\n",
    "    elif CUT_TYPE == 'filter':\n",
    "        threshold = get_bandpassThreshold(y, sr, frame_len, hoplen, thresh_factor=THRESH)\n",
    "    elif CUT_TYPE == 'none':\n",
    "        threshold = 0.0  # No threshold - accept all segments\n",
    "    else:\n",
    "        # Default to RMS if CUT_TYPE is not recognized\n",
    "        threshold = get_rmsThreshold(y, frame_len, hoplen, thresh_factor=THRESH)\n",
    "        print(f\"Warning: Unknown CUT_TYPE '{CUT_TYPE}', defaulting to 'rms'\")\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for start in range(0, len(y) - samples_per_segment + 1, samples_per_segment):\n",
    "        segment = y[start:start + samples_per_segment]\n",
    "        \n",
    "        # Apply the appropriate segment validation based on CUT_TYPE\n",
    "        if CUT_TYPE == 'rms':\n",
    "            seg_rms = np.mean(librosa.feature.rms(y=segment)[0])\n",
    "            if seg_rms >= threshold:\n",
    "                count += 1\n",
    "        elif CUT_TYPE == 'peaks':\n",
    "            if segment_has_energy_peaks(segment, threshold, sr):\n",
    "                count += 1\n",
    "        elif CUT_TYPE == 'entropy':\n",
    "            if segment_has_spectral_complexity(segment, threshold, sr):\n",
    "                count += 1\n",
    "        elif CUT_TYPE == 'filter':\n",
    "            if segment_has_bandpass_activity(segment, threshold, sr):\n",
    "                count += 1\n",
    "        elif CUT_TYPE == 'none':\n",
    "            # Accept all segments when no cutoff is applied\n",
    "            count += 1\n",
    "        else:\n",
    "            # Default to RMS validation\n",
    "            seg_rms = np.mean(librosa.feature.rms(y=segment)[0])\n",
    "            if seg_rms >= threshold:\n",
    "                count += 1\n",
    "\n",
    "    usable_segments.append(count)\n",
    "\n",
    "segs_df = rated_df.copy()\n",
    "segs_df['usable_segments'] = usable_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddab377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| scientific_name           |   samples_count |   unique_segments_count |\n",
      "|---------------------------|-----------------|-------------------------|\n",
      "| Volatinia jacarina        |              19 |                      73 |\n",
      "| Nycticorax nycticorax     |              23 |                      74 |\n",
      "| Megaceryle torquata       |              27 |                      79 |\n",
      "| Coereba flaveola          |              20 |                      82 |\n",
      "| Ramphocelus carbo         |              18 |                      86 |\n",
      "| Tyrannus melancholicus    |              22 |                      88 |\n",
      "| Piaya cayana              |              32 |                      90 |\n",
      "| Crotophaga ani            |              21 |                      98 |\n",
      "| Nyctibius griseus         |              24 |                     102 |\n",
      "| Legatus leucophaius       |              24 |                     106 |\n",
      "| Chlorospingus flavopectus |              25 |                     109 |\n",
      "| Synallaxis albescens      |              22 |                     110 |\n",
      "| Psarocolius decumanus     |              25 |                     113 |\n",
      "| Patagioenas plumbea       |              32 |                     132 |\n",
      "| Pitangus sulphuratus      |              32 |                     136 |\n",
      "| Synallaxis azarae         |              37 |                     150 |\n",
      "| Camptostoma obsoletum     |              39 |                     160 |\n",
      "| Dryocopus lineatus        |              27 |                     162 |\n",
      "| Setophaga pitiayumi       |              33 |                     170 |\n",
      "| Megarynchus pitangua      |              32 |                     183 |\n",
      "| Glaucidium brasilianum    |              32 |                     187 |\n",
      "| Thamnophilus doliatus     |              33 |                     188 |\n",
      "| Habia rubica              |              36 |                     194 |\n",
      "| Tapera naevia             |              34 |                     197 |\n",
      "| Leptotila verreauxi       |              36 |                     199 |\n",
      "| Rupornis magnirostris     |              41 |                     202 |\n",
      "| Basileuterus culicivorus  |              38 |                     205 |\n",
      "| Nyctidromus albicollis    |              32 |                     214 |\n",
      "| Sittasomus griseicapillus |              55 |                     215 |\n",
      "| Myiarchus tyrannulus      |              53 |                     218 |\n",
      "| Vanellus chilensis        |              54 |                     231 |\n",
      "| Herpetotheres cachinnans  |              19 |                     249 |\n",
      "| Myiodynastes maculatus    |              56 |                     302 |\n",
      "| Sicalis flaveola          |              55 |                     335 |\n",
      "| Tolmomyias sulphurescens  |              76 |                     384 |\n",
      "| Zonotrichia capensis      |              89 |                     394 |\n",
      "| Cyclarhis gujanensis      |              84 |                     463 |\n",
      "| Troglodytes aedon         |              61 |                     466 |\n",
      "| Saltator coerulescens     |              57 |                     467 |\n"
     ]
    }
   ],
   "source": [
    "species_sample_counts = segs_df['scientific_name'].value_counts()\n",
    "species_segment_counts = segs_df.groupby('scientific_name')['usable_segments'].sum()\n",
    "\n",
    "species_to_keep = [\n",
    "    species for species in species_sample_counts.index\n",
    "    if species_sample_counts[species] >= SAMPLES_CUTOFF and species_segment_counts[species] >= SEGMENTS_CUTOFF\n",
    "]\n",
    "\n",
    "minsmps_df = segs_df[segs_df['scientific_name'].isin(species_to_keep)].copy()\n",
    "summary_table = minsmps_df.groupby('scientific_name').agg(\n",
    "    samples_count=('scientific_name', 'count'),\n",
    "    unique_segments_count=('usable_segments', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by unique_segments_count ascending\n",
    "summary_table = summary_table.sort_values('unique_segments_count', ascending=True)\n",
    "\n",
    "# Pretty print the table\n",
    "print(tabulate(summary_table, headers='keys', tablefmt='github', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab594b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species with less than 9 unique authors (0 species):\n",
      "============================================================\n",
      "\n",
      "After filtering species with less than 9 unique authors:\n",
      "Remaining samples: 1475\n",
      "Remaining species: 39\n"
     ]
    }
   ],
   "source": [
    "# Get author counts per species\n",
    "author_counts_per_species = minsmps_df.groupby('scientific_name')['author'].nunique()\n",
    "\n",
    "# Find species with less than 2 unique authors\n",
    "species_with_few_author = author_counts_per_species[author_counts_per_species < MIN_AUTHORS_CUTOFF]\n",
    "\n",
    "print(f\"Species with less than {MIN_AUTHORS_CUTOFF} unique authors ({len(species_with_few_author)} species):\")\n",
    "print(\"=\" * 60)\n",
    "for species, author_count in species_with_few_author.items():\n",
    "    print(f\"{species}: {author_count} author(s)\")\n",
    "\n",
    "# Filter out species with less than 2 unique authors\n",
    "species_to_keep_multiauthor = author_counts_per_species[author_counts_per_species >= MIN_AUTHORS_CUTOFF].index\n",
    "authors_df = minsmps_df[minsmps_df['scientific_name'].isin(species_to_keep_multiauthor)]\n",
    "\n",
    "print(f\"\\nAfter filtering species with less than {MIN_AUTHORS_CUTOFF} unique authors:\")\n",
    "print(f\"Remaining samples: {len(authors_df)}\")\n",
    "print(f\"Remaining species: {authors_df['scientific_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c2e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (1475, 7)\n",
      "Final number of samples: 1475\n",
      "Final number of usable segments: 7613\n",
      "Final number of species: 39\n"
     ]
    }
   ],
   "source": [
    "# Load the Class IDs for training\n",
    "final_df = authors_df[['primary_label', 'scientific_name', 'common_name', 'filename', 'author', 'usable_segments']].copy()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "final_df['class_id'] = le.fit_transform(final_df['scientific_name'])\n",
    "\n",
    "# Save species to CSV\n",
    "final_df.to_csv(os.path.join('..', 'database', 'meta', 'final_species.csv'), index=False)\n",
    "\n",
    "# Build mapping with class_id, scientific_name, common_name\n",
    "mapping_df = final_df[['class_id', 'scientific_name', 'common_name']].drop_duplicates().sort_values('class_id')\n",
    "mapping_df.to_csv(os.path.join('..', 'database', 'meta', 'class_mapping.csv'), index=False)\n",
    "\n",
    "print(f\"Final DataFrame shape: {final_df.shape}\")\n",
    "print(f\"Final number of samples: {len(final_df)}\")\n",
    "print(f\"Final number of usable segments: {final_df['usable_segments'].sum()}\")\n",
    "print(f\"Final number of species: {final_df['scientific_name'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
