{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1729b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.models import BirdCNN, BirdResNet\n",
    "from utils.dataset_utils import get_spect_matrix_list, StandardizedDataset\n",
    "from utils.training_utils import train_single_fold, EarlyStopping, fast_single_fold_training_with_augmentation\n",
    "from utils.cross_validation import k_fold_cross_validation_with_predefined_folds\n",
    "from utils.evaluation_utils import plot_kfold_results, save_model, load_model, plot_single_fold_curve, print_single_fold_results, plot_confusion_matrix, print_confusion_matrix_stats\n",
    "from utils.data_processing import load_spectrograms_from_csv\n",
    "import utils.split as split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.dataset_utils\n",
    "import utils.training_utils\n",
    "import utils.cross_validation\n",
    "import utils.evaluation_utils\n",
    "import utils.data_processing\n",
    "import utils.split\n",
    "import utils.models\n",
    "\n",
    "importlib.reload(utils.dataset_utils)\n",
    "importlib.reload(utils.training_utils)\n",
    "importlib.reload(utils.cross_validation)\n",
    "importlib.reload(utils.evaluation_utils)\n",
    "importlib.reload(utils.data_processing)\n",
    "importlib.reload(utils.split)\n",
    "importlib.reload(utils.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectrogram data and metadata\n",
    "spect_dir = os.path.join('..', 'database', 'spect')  # Spectrogram PNG directory\n",
    "spects_df = pd.read_csv(os.path.join('..', 'database', 'meta', 'final_spects.csv'))  # Metadata\n",
    "\n",
    "print(\"Loading spectrograms directly into matrices...\")\n",
    "matrices_list, labels_list, authors_list = get_spect_matrix_list(spect_dir, spects_df)\n",
    "\n",
    "print(f\"Loaded {len(matrices_list)} spectrograms\")\n",
    "print(f\"Matrix shape: {matrices_list[0].shape}\")\n",
    "print(f\"Unique labels: {len(set(labels_list))}\")\n",
    "print(f\"Unique authors: {len(set(authors_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for training\n",
    "labels = np.array(labels_list, dtype=np.int64)\n",
    "authors = np.array(authors_list)\n",
    "\n",
    "# Convert matrices to numpy array and normalize\n",
    "features = np.array(matrices_list, dtype=np.float32)\n",
    "# Convert to 0-1 range first, then standardization will be applied per fold\n",
    "features /= 255.0\n",
    "# Reshape to add channel dimension for CNN: (samples, channels, height, width)\n",
    "features = features.reshape(-1, 1, 224, 313)\n",
    "\n",
    "print(\"features shape:\", features.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"authors shape:\", authors.shape)\n",
    "\n",
    "# Create metadata DataFrame for splitting (with sample indices)\n",
    "metadata_df = pd.DataFrame({\n",
    "    'sample_idx': range(len(labels)),\n",
    "    'class_id': labels,\n",
    "    'author': authors,\n",
    "    'usable_segments': 1  # Each sample represents 1 segment\n",
    "})\n",
    "\n",
    "print(\"metadata_df shape:\", metadata_df.shape)\n",
    "print(\"Unique authors:\", len(metadata_df['author'].unique()))\n",
    "print(\"Unique classes:\", len(metadata_df['class_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules to pick up any changes\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(util)\n",
    "importlib.reload(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensors for PyTorch\n",
    "X_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"Tensor shapes: X={X_tensor.shape}, y={y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48784347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best 80-20 split using author grouping\n",
    "print(\"Finding best 80-20 split with author grouping...\")\n",
    "dev_df, test_df, best_split_score = split.search_best_group_seed(\n",
    "    df=metadata_df,\n",
    "    test_size=0.2,\n",
    "    max_attempts=5_000,\n",
    "    min_test_segments=3\n",
    ")\n",
    "\n",
    "# Extract indices for single fold training\n",
    "train_indices_single = dev_df['sample_idx'].values\n",
    "val_indices_single = test_df['sample_idx'].values\n",
    "\n",
    "print(f\"Best 80-20 split found with score: {best_split_score:.3f}\")\n",
    "print(f\"Train samples: {len(train_indices_single)}, Validation samples: {len(val_indices_single)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimized training function performance\n",
    "import time\n",
    "\n",
    "print(\"Testing optimized training function startup time...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a small test to measure overhead\n",
    "test_indices = train_indices_single[:100] if len(train_indices_single) > 100 else train_indices_single[:50]\n",
    "test_val_indices = val_indices_single[:20] if len(val_indices_single) > 20 else val_indices_single[:10]\n",
    "\n",
    "print(f\"Test dataset size: Train={len(test_indices)}, Val={len(test_val_indices)}\")\n",
    "\n",
    "# Measure just the data loading and setup overhead\n",
    "print(\"\\nTiming data loader creation...\")\n",
    "loader_start = time.time()\n",
    "\n",
    "# Create standardized subset directly to test\n",
    "if True:  # Test standardization path\n",
    "    sample_size = min(50, len(test_indices))\n",
    "    sample_indices = np.random.choice(test_indices, sample_size, replace=False)\n",
    "    sample_data = torch.stack([dataset[i][0] for i in sample_indices])\n",
    "    train_mean = sample_data.mean()\n",
    "    train_std = sample_data.std()\n",
    "    \n",
    "    class StandardizedSubset(torch.utils.data.Dataset):\n",
    "        def __init__(self, original_dataset, indices, mean, std):\n",
    "            self.dataset = original_dataset\n",
    "            self.indices = list(indices)  # Convert to list for compatibility\n",
    "            self.mean = mean\n",
    "            self.std = std + 1e-8\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.indices)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            real_idx = self.indices[idx]\n",
    "            x, y = self.dataset[real_idx]\n",
    "            x_standardized = (x - self.mean) / self.std\n",
    "            return x_standardized, y\n",
    "    \n",
    "    test_train_subset = StandardizedSubset(dataset, test_indices, train_mean, train_std)\n",
    "    test_val_subset = StandardizedSubset(dataset, test_val_indices, train_mean, train_std)\n",
    "else:\n",
    "    from torch.utils.data import Subset\n",
    "    test_train_subset = Subset(dataset, test_indices)\n",
    "    test_val_subset = Subset(dataset, test_val_indices)\n",
    "\n",
    "# Test DataLoader creation with single thread to avoid worker crashes\n",
    "test_train_loader = torch.utils.data.DataLoader(\n",
    "    test_train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Use single thread to avoid worker crashes\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Use single thread to avoid worker crashes\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "loader_time = time.time() - loader_start\n",
    "print(f\"DataLoader creation time: {loader_time:.2f} seconds\")\n",
    "\n",
    "# Test first batch loading\n",
    "print(\"Testing first batch loading...\")\n",
    "batch_start = time.time()\n",
    "try:\n",
    "    test_batch = next(iter(test_train_loader))\n",
    "    batch_time = time.time() - batch_start\n",
    "    print(f\"First batch loading time: {batch_time:.2f} seconds\")\n",
    "    print(f\"Batch shape: {test_batch[0].shape}\")\n",
    "    print(\"✓ DataLoader working correctly!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")\n",
    "    print(\"Falling back to direct dataset access...\")\n",
    "    batch_start = time.time()\n",
    "    test_sample = test_train_subset[0]\n",
    "    batch_time = time.time() - batch_start\n",
    "    print(f\"Direct dataset access time: {batch_time:.4f} seconds\")\n",
    "    print(f\"Sample shape: {test_sample[0].shape}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal test time: {total_time:.2f} seconds\")\n",
    "print(\"Optimization complete - training should start much faster now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e2281",
   "metadata": {},
   "source": [
    "## Single Fold Training with Predefined Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that author grouping is preserved in our splits\n",
    "print(\"Verifying author grouping in predefined splits...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get authors for training and validation sets\n",
    "train_authors = set(metadata_df.loc[metadata_df['sample_idx'].isin(train_indices_single), 'author'])\n",
    "val_authors = set(metadata_df.loc[metadata_df['sample_idx'].isin(val_indices_single), 'author'])\n",
    "\n",
    "# Check for overlap\n",
    "author_overlap = train_authors & val_authors\n",
    "print(f\"Training set authors: {len(train_authors)} unique authors\")\n",
    "print(f\"Validation set authors: {len(val_authors)} unique authors\")\n",
    "print(f\"Author overlap between train/val: {len(author_overlap)} authors\")\n",
    "\n",
    "if len(author_overlap) == 0:\n",
    "    print(\"✓ PERFECT: No author overlap - authors are properly grouped!\")\n",
    "else:\n",
    "    print(f\"⚠️ WARNING: {len(author_overlap)} authors appear in both sets\")\n",
    "    print(f\"Overlapping authors: {author_overlap}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_classes = set(metadata_df.loc[metadata_df['sample_idx'].isin(train_indices_single), 'class_id'])\n",
    "val_classes = set(metadata_df.loc[metadata_df['sample_idx'].isin(val_indices_single), 'class_id'])\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training set classes: {len(train_classes)} classes\")\n",
    "print(f\"Validation set classes: {len(val_classes)} classes\")\n",
    "print(f\"All classes present in both sets: {train_classes == val_classes}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Both optimized functions use these SAME predefined author-grouped splits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde9b2",
   "metadata": {},
   "source": [
    "Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07947fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run original (now optimized) single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "print(\"Using OPTIMIZED original function with predefined author-grouped splits...\")\n",
    "print(f\"Train indices: {len(train_indices)} samples\")\n",
    "print(f\"Val indices: {len(val_indices)} samples\")\n",
    "\n",
    "# Use the fast training function to avoid multiprocessing issues\n",
    "single_results_original = train_single_fold(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for original optimized function\n",
    "from utils.evaluation_utils import plot_single_fold_curve, print_single_fold_results, plot_confusion_matrix, print_confusion_matrix_stats\n",
    "\n",
    "plot_single_fold_curve(single_results_original, metric_key='accuracies', title=\"Original Optimized - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "plot_single_fold_curve(single_results_original, metric_key='losses', title=\"Original Optimized - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "plot_single_fold_curve(single_results_original, metric_key='f1s', title=\"Original Optimized - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "print_single_fold_results(single_results_original)\n",
    "\n",
    "# Display confusion matrix\n",
    "plot_confusion_matrix(single_results_original['confusion_matrix'], title=\"BirdCNN Original Optimized - Validation Confusion Matrix\")\n",
    "print_confusion_matrix_stats(single_results_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FAST single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "# Use the optimized fast training function\n",
    "single_results = train_single_fold(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves\n",
    "plot_single_fold_curve(single_results, metric_key='accuracies', title=\"Single Fold - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "plot_single_fold_curve(single_results, metric_key='losses', title=\"Single Fold - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "plot_single_fold_curve(single_results, metric_key='f1s', title=\"Single Fold - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "print_single_fold_results(single_results)\n",
    "\n",
    "# Display confusion matrix\n",
    "plot_confusion_matrix(single_results['confusion_matrix'], title=\"BirdCNN - Validation Confusion Matrix\")\n",
    "print_confusion_matrix_stats(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = train_single_fold(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=BirdResNet,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=False,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "plot_single_fold_curve(single_results, metric_key='accuracies', title=\"BirdRes - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "plot_single_fold_curve(single_results, metric_key='losses', title=\"BirdRes - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "plot_single_fold_curve(single_results, metric_key='f1s', title=\"BirdRes - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "print_single_fold_results(single_results)\n",
    "\n",
    "# Display confusion matrix\n",
    "plot_confusion_matrix(single_results['confusion_matrix'], title=\"BirdResNet - Validation Confusion Matrix\")\n",
    "print_confusion_matrix_stats(single_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1506e9",
   "metadata": {},
   "source": [
    "## SpecAugment Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SpecAugment\n",
    "import importlib\n",
    "from utils.specaugment import get_recommended_params, visualize_specaugment\n",
    "\n",
    "# Reload modules\n",
    "importlib.reload(utils.training_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommended SpecAugment parameters for your dataset\n",
    "total_samples = len(metadata_df)\n",
    "num_classes_actual = len(set(labels_list))\n",
    "\n",
    "recommended_params = get_recommended_params(\n",
    "    num_samples=total_samples,\n",
    "    num_classes=num_classes_actual,\n",
    "    input_size=(224, 313)\n",
    ")\n",
    "\n",
    "print(f\"Dataset statistics:\")\n",
    "print(f\"  Total samples: {total_samples}\")\n",
    "print(f\"  Number of classes: {num_classes_actual}\")\n",
    "print(f\"  Samples per class (avg): {total_samples / num_classes_actual:.1f}\")\n",
    "\n",
    "print(f\"\\nRecommended SpecAugment parameters:\")\n",
    "for key, value in recommended_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SpecAugment visualization on actual data\n",
    "print(\"Testing SpecAugment on actual training data...\")\n",
    "\n",
    "# Get a sample from the dataset\n",
    "sample_idx = 0\n",
    "sample_spec, sample_label = dataset[sample_idx]\n",
    "\n",
    "print(f\"Sample shape: {sample_spec.shape}\")\n",
    "print(f\"Sample label: {sample_label}\")\n",
    "\n",
    "# Apply SpecAugment\n",
    "from utils.specaugment import SpecAugment\n",
    "augmenter = SpecAugment(**recommended_params)\n",
    "augmented_spec = augmenter(sample_spec)\n",
    "\n",
    "# Visualize\n",
    "visualize_specaugment(\n",
    "    sample_spec.squeeze(0),  # Remove channel dimension for visualization\n",
    "    augmented_spec.squeeze(0),\n",
    "    title=f\"SpecAugment on Training Data - Class {sample_label}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BirdCNN with SpecAugment using predefined author-grouped splits\n",
    "print(\"Training BirdCNN with SpecAugment and author-grouped splits...\")\n",
    "\n",
    "# Use the same train/val indices from earlier\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "# Train with SpecAugment\n",
    "results_with_augment = fast_single_fold_training_with_augmentation(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True,\n",
    "    augment_params=recommended_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf98d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves with SpecAugment\n",
    "plot_single_fold_curve(results_with_augment, metric_key='accuracies', title=\"SpecAugment - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "plot_single_fold_curve(results_with_augment, metric_key='losses', title=\"SpecAugment - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "plot_single_fold_curve(results_with_augment, metric_key='f1s', title=\"SpecAugment - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results\n",
    "print_single_fold_results(results_with_augment)\n",
    "\n",
    "# Display confusion matrix\n",
    "plot_confusion_matrix(results_with_augment['confusion_matrix'], title=\"BirdCNN with SpecAugment - Validation Confusion Matrix\")\n",
    "print_confusion_matrix_stats(results_with_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75feab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results: Original vs SpecAugment\n",
    "print(\"COMPARISON: Original vs SpecAugment Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'single_results' in locals():\n",
    "    print(\"Original Training (without SpecAugment):\")\n",
    "    print(f\"  Final Val Accuracy: {single_results['final_val_acc']:.4f}\")\n",
    "    print(f\"  Final Val F1 Score: {single_results['final_val_f1']:.4f}\")\n",
    "    print(f\"  Best Val Accuracy: {single_results['best_val_acc']:.4f}\")\n",
    "    print(f\"  Best Val F1 Score: {single_results['best_val_f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nWith SpecAugment:\")\n",
    "    print(f\"  Final Val Accuracy: {results_with_augment['final_val_acc']:.4f}\")\n",
    "    print(f\"  Final Val F1 Score: {results_with_augment['final_val_f1']:.4f}\")\n",
    "    print(f\"  Best Val Accuracy: {results_with_augment['best_val_acc']:.4f}\")\n",
    "    print(f\"  Best Val F1 Score: {results_with_augment['best_val_f1']:.4f}\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    acc_improvement = results_with_augment['final_val_acc'] - single_results['final_val_acc']\n",
    "    f1_improvement = results_with_augment['final_val_f1'] - single_results['final_val_f1']\n",
    "    \n",
    "    print(f\"\\nImprovement with SpecAugment:\")\n",
    "    print(f\"  Accuracy: {acc_improvement:+.4f}\")\n",
    "    print(f\"  F1 Score: {f1_improvement:+.4f}\")\n",
    "else:\n",
    "    print(\"Run the original training first to compare results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SpecAugment parameters experiment\n",
    "print(\"Experimenting with more aggressive SpecAugment parameters...\")\n",
    "\n",
    "# More aggressive parameters for experimentation\n",
    "aggressive_params = {\n",
    "    'time_mask_param': 60,  # Larger time masks\n",
    "    'freq_mask_param': 20,  # Larger frequency masks\n",
    "    'num_time_masks': 2,    # Multiple time masks\n",
    "    'num_freq_masks': 1,\n",
    "    'mask_value': 0.0,\n",
    "    'p': 0.9               # Higher probability\n",
    "}\n",
    "\n",
    "print(f\"Aggressive SpecAugment parameters: {aggressive_params}\")\n",
    "\n",
    "# Train with aggressive parameters\n",
    "results_aggressive = fast_single_fold_training_with_augmentation(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=200,  # Shorter training for experimentation\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True,\n",
    "    augment_params=aggressive_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all SpecAugment variants\n",
    "print(\"COMPARISON: Recommended vs Aggressive SpecAugment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Recommended SpecAugment:\")\n",
    "print(f\"  Final Val Accuracy: {results_with_augment['final_val_acc']:.4f}\")\n",
    "print(f\"  Final Val F1 Score: {results_with_augment['final_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nAggressive SpecAugment:\")\n",
    "print(f\"  Final Val Accuracy: {results_aggressive['final_val_acc']:.4f}\")\n",
    "print(f\"  Final Val F1 Score: {results_aggressive['final_val_f1']:.4f}\")\n",
    "\n",
    "# Determine which is better\n",
    "if results_aggressive['final_val_f1'] > results_with_augment['final_val_f1']:\n",
    "    print(f\"\\n✓ Aggressive parameters perform better!\")\n",
    "    best_augment_results = results_aggressive\n",
    "    best_params = aggressive_params\n",
    "else:\n",
    "    print(f\"\\n✓ Recommended parameters perform better!\")\n",
    "    best_augment_results = results_with_augment\n",
    "    best_params = recommended_params\n",
    "\n",
    "print(f\"Best SpecAugment parameters: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
