{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1729b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 5080\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import util, models, split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29cf9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spect_matrix_list(spects_source_dir, spects_meta_df):\n",
    "    \"\"\"\n",
    "    Load spectrograms directly as matrices without flattening to CSV.\n",
    "    \n",
    "    Args:\n",
    "        spects_source_dir (str): Directory where the spectrogram images are stored in .png format\n",
    "        spects_meta_df (pd.DataFrame): DataFrame with columns 'filename', 'class_id', and 'author'\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (matrices_list, labels_list, authors_list)\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    matrices_list = []\n",
    "    labels_list = []\n",
    "    authors_list = []\n",
    "    \n",
    "    spects_meta_df = spects_meta_df.dropna(subset=['filename', 'class_id', 'author'])\n",
    "\n",
    "    print(f\"Processing {len(spects_meta_df)} spectrograms...\")\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for _, row in spects_meta_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        class_id = row['class_id']\n",
    "        author = row['author']\n",
    "\n",
    "        image_path = os.path.join(spects_source_dir, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"File not found: {image_path}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        img = Image.open(image_path).convert('L')  # Ensure grayscale\n",
    "        \n",
    "        expected_shape = (313, 224)  # PIL uses (width, height) format\n",
    "        if img.size != expected_shape:\n",
    "            print(f\"Warning: Unexpected image size: {img.size} in file {image_path}. Expected {expected_shape}.\")\n",
    "            # Resize if needed\n",
    "            img = img.resize(expected_shape)\n",
    "\n",
    "        # Convert to numpy array (this gives us height x width, i.e., 313 x 224)\n",
    "        pixels = np.array(img)\n",
    "        \n",
    "        matrices_list.append(pixels)\n",
    "        labels_list.append(class_id)\n",
    "        authors_list.append(author)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Skipped: {skipped_count}\")\n",
    "\n",
    "    if not matrices_list:\n",
    "        raise ValueError(\"No spectrograms were loaded. Check paths and metadata consistency.\")\n",
    "\n",
    "    return matrices_list, labels_list, authors_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29b5b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spectrograms directly into matrices...\n",
      "Processing 2387 spectrograms...\n",
      "Successfully processed: 2387\n",
      "Skipped: 0\n",
      "Loaded 2387 spectrograms\n",
      "Matrix shape: (224, 313)\n",
      "Unique labels: 31\n",
      "Unique authors: 75\n",
      "Successfully processed: 2387\n",
      "Skipped: 0\n",
      "Loaded 2387 spectrograms\n",
      "Matrix shape: (224, 313)\n",
      "Unique labels: 31\n",
      "Unique authors: 75\n"
     ]
    }
   ],
   "source": [
    "# Load spectrogram data and metadata\n",
    "spect_dir = os.path.join('..', 'database', 'spect')  # Spectrogram PNG directory\n",
    "spects_df = pd.read_csv(os.path.join('..', 'database', 'meta', 'final_spects.csv'))  # Metadata\n",
    "\n",
    "print(\"Loading spectrograms directly into matrices...\")\n",
    "matrices_list, labels_list, authors_list = get_spect_matrix_list(spect_dir, spects_df)\n",
    "\n",
    "print(f\"Loaded {len(matrices_list)} spectrograms\")\n",
    "print(f\"Matrix shape: {matrices_list[0].shape}\")\n",
    "print(f\"Unique labels: {len(set(labels_list))}\")\n",
    "print(f\"Unique authors: {len(set(authors_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (2387, 1, 224, 313)\n",
      "labels shape: (2387,)\n",
      "authors shape: (2387,)\n",
      "metadata_df shape: (2387, 4)\n",
      "Unique authors: 75\n",
      "Unique classes: 31\n"
     ]
    }
   ],
   "source": [
    "# Process data for training\n",
    "labels = np.array(labels_list, dtype=np.int64)\n",
    "authors = np.array(authors_list)\n",
    "\n",
    "# Convert matrices to numpy array and normalize\n",
    "features = np.array(matrices_list, dtype=np.float32)\n",
    "# Convert to 0-1 range first, then standardization will be applied per fold\n",
    "features /= 255.0\n",
    "# Reshape to add channel dimension for CNN: (samples, channels, height, width)\n",
    "features = features.reshape(-1, 1, 313, 224)\n",
    "\n",
    "print(\"features shape:\", features.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"authors shape:\", authors.shape)\n",
    "\n",
    "# Create metadata DataFrame for splitting (with sample indices)\n",
    "metadata_df = pd.DataFrame({\n",
    "    'sample_idx': range(len(labels)),\n",
    "    'class_id': labels,\n",
    "    'author': authors,\n",
    "    'usable_segments': 1  # Each sample represents 1 segment\n",
    "})\n",
    "\n",
    "print(\"metadata_df shape:\", metadata_df.shape)\n",
    "print(\"Unique authors:\", len(metadata_df['author'].unique()))\n",
    "print(\"Unique classes:\", len(metadata_df['class_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e46008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules to pick up any changes\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(util)\n",
    "importlib.reload(split)\n",
    "\n",
    "# Reload to pick up the StandardizedDataset fix and scheduler changes\n",
    "from utils import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e59a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 2387 samples\n",
      "Tensor shapes: X=torch.Size([2387, 1, 224, 313]), y=torch.Size([2387])\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensors for PyTorch\n",
    "X_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"Tensor shapes: X={X_tensor.shape}, y={y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48784347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best 80-20 split using author grouping\n",
    "print(\"Finding best 80-20 split with author grouping...\")\n",
    "dev_df, test_df, best_split_score = split.search_best_group_seed(\n",
    "    df=metadata_df,\n",
    "    test_size=0.15,\n",
    "    max_attempts=25_000,\n",
    "    min_test_segments=3\n",
    ")\n",
    "\n",
    "# Extract indices for single fold training\n",
    "train_indices_single = dev_df['sample_idx'].values\n",
    "val_indices_single = test_df['sample_idx'].values\n",
    "\n",
    "print(f\"Best 80-20 split found with score: {best_split_score:.3f}\")\n",
    "print(f\"Train samples: {len(train_indices_single)}, Validation samples: {len(val_indices_single)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e2281",
   "metadata": {},
   "source": [
    "## Single Fold Training with Predefined Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07947fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Dataset size: 2387\n",
      "Train size: 1809, Val size: 578\n",
      "Using standardization based on training data statistics\n",
      "Training data statistics - Mean: 0.1540, Std: 0.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/250 [00:00<?, ?epoch/s]"
     ]
    }
   ],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = util.single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=False,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"Single Fold - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"Single Fold - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"Single Fold - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = util.single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db767ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"Single Fold - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"Single Fold - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"Single Fold - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6211313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = util.single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdResNet,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77472771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"BirdRes - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"BirdRes - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"BirdRes - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = util.single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdResNet,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=False,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"BirdRes - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"BirdRes - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"BirdRes - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d924f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with regular 80-20 stratified split\n",
    "single_results_80_20 = util.single_fold_training(\n",
    "    dataset=dataset,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=31,\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    test_size=0.2,\n",
    "    random_state=435,\n",
    "    use_class_weights=False,\n",
    "    estop=35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for 80-20 split\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='accuracies', title=\"80-20 Split - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='losses', title=\"80-20 Split - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='f1s', title=\"80-20 Split - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results_80_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with regular 80-20 stratified split\n",
    "single_results_80_20 = util.single_fold_training(\n",
    "    dataset=dataset,\n",
    "    model_class=models.BirdResNet,\n",
    "    num_classes=31,\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    test_size=0.2,\n",
    "    random_state=435,\n",
    "    use_class_weights=False,\n",
    "    estop=35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for 80-20 split\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='accuracies', title=\"80-20 Split - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='losses', title=\"80-20 Split - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results_80_20, metric_key='f1s', title=\"80-20 Split - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results_80_20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
