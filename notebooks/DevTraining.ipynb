{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1729b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import util, models, split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(util)\n",
    "importlib.reload(models)\n",
    "importlib.reload(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spect_matrix_list(spects_source_dir, spects_meta_df):\n",
    "    \"\"\"\n",
    "    Load spectrograms directly as matrices without flattening to CSV.\n",
    "    \n",
    "    Args:\n",
    "        spects_source_dir (str): Directory where the spectrogram images are stored in .png format\n",
    "        spects_meta_df (pd.DataFrame): DataFrame with columns 'filename', 'class_id', and 'author'\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (matrices_list, labels_list, authors_list)\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    matrices_list = []\n",
    "    labels_list = []\n",
    "    authors_list = []\n",
    "    \n",
    "    spects_meta_df = spects_meta_df.dropna(subset=['filename', 'class_id', 'author'])\n",
    "\n",
    "    print(f\"Processing {len(spects_meta_df)} spectrograms...\")\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for _, row in spects_meta_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        class_id = row['class_id']\n",
    "        author = row['author']\n",
    "\n",
    "        image_path = os.path.join(spects_source_dir, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"File not found: {image_path}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        img = Image.open(image_path).convert('L')  # Ensure grayscale\n",
    "        \n",
    "        expected_shape = (313, 224)  # PIL uses (width, height) format\n",
    "        if img.size != expected_shape:\n",
    "            print(f\"Warning: Unexpected image size: {img.size} in file {image_path}. Expected {expected_shape}.\")\n",
    "            # Resize if needed\n",
    "            img = img.resize(expected_shape)\n",
    "\n",
    "        # Convert to numpy array (this gives us height x width, i.e., 313 x 224)\n",
    "        pixels = np.array(img)\n",
    "        \n",
    "        matrices_list.append(pixels)\n",
    "        labels_list.append(class_id)\n",
    "        authors_list.append(author)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Skipped: {skipped_count}\")\n",
    "\n",
    "    if not matrices_list:\n",
    "        raise ValueError(\"No spectrograms were loaded. Check paths and metadata consistency.\")\n",
    "\n",
    "    return matrices_list, labels_list, authors_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectrogram data and metadata\n",
    "spect_dir = os.path.join('..', 'database', 'spect')  # Spectrogram PNG directory\n",
    "spects_df = pd.read_csv(os.path.join('..', 'database', 'meta', 'final_spects.csv'))  # Metadata\n",
    "\n",
    "print(\"Loading spectrograms directly into matrices...\")\n",
    "matrices_list, labels_list, authors_list = get_spect_matrix_list(spect_dir, spects_df)\n",
    "\n",
    "print(f\"Loaded {len(matrices_list)} spectrograms\")\n",
    "print(f\"Matrix shape: {matrices_list[0].shape}\")\n",
    "print(f\"Unique labels: {len(set(labels_list))}\")\n",
    "print(f\"Unique authors: {len(set(authors_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for training\n",
    "labels = np.array(labels_list, dtype=np.int64)\n",
    "authors = np.array(authors_list)\n",
    "\n",
    "# Convert matrices to numpy array and normalize\n",
    "features = np.array(matrices_list, dtype=np.float32)\n",
    "# Convert to 0-1 range first, then standardization will be applied per fold\n",
    "features /= 255.0\n",
    "# Reshape to add channel dimension for CNN: (samples, channels, height, width)\n",
    "features = features.reshape(-1, 1, 224, 313)\n",
    "\n",
    "print(\"features shape:\", features.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"authors shape:\", authors.shape)\n",
    "\n",
    "# Create metadata DataFrame for splitting (with sample indices)\n",
    "metadata_df = pd.DataFrame({\n",
    "    'sample_idx': range(len(labels)),\n",
    "    'class_id': labels,\n",
    "    'author': authors,\n",
    "    'usable_segments': 1  # Each sample represents 1 segment\n",
    "})\n",
    "\n",
    "print(\"metadata_df shape:\", metadata_df.shape)\n",
    "print(\"Unique authors:\", len(metadata_df['author'].unique()))\n",
    "print(\"Unique classes:\", len(metadata_df['class_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules to pick up any changes\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(util)\n",
    "importlib.reload(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensors for PyTorch\n",
    "X_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"Tensor shapes: X={X_tensor.shape}, y={y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48784347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best 80-20 split using author grouping\n",
    "print(\"Finding best 80-20 split with author grouping...\")\n",
    "dev_df, test_df, best_split_score = split.search_best_group_seed(\n",
    "    df=metadata_df,\n",
    "    test_size=0.2,\n",
    "    max_attempts=5_000,\n",
    "    min_test_segments=3\n",
    ")\n",
    "\n",
    "# Extract indices for single fold training\n",
    "train_indices_single = dev_df['sample_idx'].values\n",
    "val_indices_single = test_df['sample_idx'].values\n",
    "\n",
    "print(f\"Best 80-20 split found with score: {best_split_score:.3f}\")\n",
    "print(f\"Train samples: {len(train_indices_single)}, Validation samples: {len(val_indices_single)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimized training function performance\n",
    "import time\n",
    "\n",
    "print(\"Testing optimized training function startup time...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a small test to measure overhead\n",
    "test_indices = train_indices_single[:100] if len(train_indices_single) > 100 else train_indices_single[:50]\n",
    "test_val_indices = val_indices_single[:20] if len(val_indices_single) > 20 else val_indices_single[:10]\n",
    "\n",
    "print(f\"Test dataset size: Train={len(test_indices)}, Val={len(test_val_indices)}\")\n",
    "\n",
    "# Measure just the data loading and setup overhead\n",
    "print(\"\\nTiming data loader creation...\")\n",
    "loader_start = time.time()\n",
    "\n",
    "# Create standardized subset directly to test\n",
    "if True:  # Test standardization path\n",
    "    sample_size = min(50, len(test_indices))\n",
    "    sample_indices = np.random.choice(test_indices, sample_size, replace=False)\n",
    "    sample_data = torch.stack([dataset[i][0] for i in sample_indices])\n",
    "    train_mean = sample_data.mean()\n",
    "    train_std = sample_data.std()\n",
    "    \n",
    "    class StandardizedSubset(torch.utils.data.Dataset):\n",
    "        def __init__(self, original_dataset, indices, mean, std):\n",
    "            self.dataset = original_dataset\n",
    "            self.indices = list(indices)  # Convert to list for compatibility\n",
    "            self.mean = mean\n",
    "            self.std = std + 1e-8\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.indices)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            real_idx = self.indices[idx]\n",
    "            x, y = self.dataset[real_idx]\n",
    "            x_standardized = (x - self.mean) / self.std\n",
    "            return x_standardized, y\n",
    "    \n",
    "    test_train_subset = StandardizedSubset(dataset, test_indices, train_mean, train_std)\n",
    "    test_val_subset = StandardizedSubset(dataset, test_val_indices, train_mean, train_std)\n",
    "else:\n",
    "    from torch.utils.data import Subset\n",
    "    test_train_subset = Subset(dataset, test_indices)\n",
    "    test_val_subset = Subset(dataset, test_val_indices)\n",
    "\n",
    "# Test DataLoader creation with single thread to avoid worker crashes\n",
    "test_train_loader = torch.utils.data.DataLoader(\n",
    "    test_train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Use single thread to avoid worker crashes\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Use single thread to avoid worker crashes\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "loader_time = time.time() - loader_start\n",
    "print(f\"DataLoader creation time: {loader_time:.2f} seconds\")\n",
    "\n",
    "# Test first batch loading\n",
    "print(\"Testing first batch loading...\")\n",
    "batch_start = time.time()\n",
    "try:\n",
    "    test_batch = next(iter(test_train_loader))\n",
    "    batch_time = time.time() - batch_start\n",
    "    print(f\"First batch loading time: {batch_time:.2f} seconds\")\n",
    "    print(f\"Batch shape: {test_batch[0].shape}\")\n",
    "    print(\"✓ DataLoader working correctly!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")\n",
    "    print(\"Falling back to direct dataset access...\")\n",
    "    batch_start = time.time()\n",
    "    test_sample = test_train_subset[0]\n",
    "    batch_time = time.time() - batch_start\n",
    "    print(f\"Direct dataset access time: {batch_time:.4f} seconds\")\n",
    "    print(f\"Sample shape: {test_sample[0].shape}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal test time: {total_time:.2f} seconds\")\n",
    "print(\"Optimization complete - training should start much faster now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e2281",
   "metadata": {},
   "source": [
    "## Single Fold Training with Predefined Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that author grouping is preserved in our splits\n",
    "print(\"Verifying author grouping in predefined splits...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get authors for training and validation sets\n",
    "train_authors = set(metadata_df.loc[metadata_df['sample_idx'].isin(train_indices_single), 'author'])\n",
    "val_authors = set(metadata_df.loc[metadata_df['sample_idx'].isin(val_indices_single), 'author'])\n",
    "\n",
    "# Check for overlap\n",
    "author_overlap = train_authors & val_authors\n",
    "print(f\"Training set authors: {len(train_authors)} unique authors\")\n",
    "print(f\"Validation set authors: {len(val_authors)} unique authors\")\n",
    "print(f\"Author overlap between train/val: {len(author_overlap)} authors\")\n",
    "\n",
    "if len(author_overlap) == 0:\n",
    "    print(\"✓ PERFECT: No author overlap - authors are properly grouped!\")\n",
    "else:\n",
    "    print(f\"⚠️ WARNING: {len(author_overlap)} authors appear in both sets\")\n",
    "    print(f\"Overlapping authors: {author_overlap}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_classes = set(metadata_df.loc[metadata_df['sample_idx'].isin(train_indices_single), 'class_id'])\n",
    "val_classes = set(metadata_df.loc[metadata_df['sample_idx'].isin(val_indices_single), 'class_id'])\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training set classes: {len(train_classes)} classes\")\n",
    "print(f\"Validation set classes: {len(val_classes)} classes\")\n",
    "print(f\"All classes present in both sets: {train_classes == val_classes}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Both optimized functions use these SAME predefined author-grouped splits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde9b2",
   "metadata": {},
   "source": [
    "Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07947fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run original (now optimized) single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "print(\"Using OPTIMIZED original function with predefined author-grouped splits...\")\n",
    "print(f\"Train indices: {len(train_indices)} samples\")\n",
    "print(f\"Val indices: {len(val_indices)} samples\")\n",
    "\n",
    "# Use the fast training function to avoid multiprocessing issues\n",
    "single_results_original = util.fast_single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for original optimized function\n",
    "util.plot_single_fold_curve(single_results_original, metric_key='accuracies', title=\"Original Optimized - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results_original, metric_key='losses', title=\"Original Optimized - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results_original, metric_key='f1s', title=\"Original Optimized - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results_original)\n",
    "\n",
    "# Display confusion matrix\n",
    "util.plot_confusion_matrix(single_results_original['confusion_matrix'], title=\"BirdCNN Original Optimized - Validation Confusion Matrix\")\n",
    "util.print_confusion_matrix_stats(single_results_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FAST single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "# Use the optimized fast training function\n",
    "single_results = util.fast_single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"Single Fold - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"Single Fold - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"Single Fold - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)\n",
    "\n",
    "# Display confusion matrix\n",
    "util.plot_confusion_matrix(single_results['confusion_matrix'], title=\"BirdCNN - Validation Confusion Matrix\")\n",
    "util.print_confusion_matrix_stats(single_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single fold training with best 80-20 split found above\n",
    "# This uses the optimal train/validation split with author grouping\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "single_results = util.fast_single_fold_training_with_predefined_split(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdResNet,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=False,\n",
    "    estop=35,\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fa950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual training curves for single fold\n",
    "util.plot_single_fold_curve(single_results, metric_key='accuracies', title=\"BirdRes - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='losses', title=\"BirdRes - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(single_results, metric_key='f1s', title=\"BirdRes - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results summary\n",
    "util.print_single_fold_results(single_results)\n",
    "\n",
    "# Display confusion matrix\n",
    "util.plot_confusion_matrix(single_results['confusion_matrix'], title=\"BirdResNet - Validation Confusion Matrix\")\n",
    "util.print_confusion_matrix_stats(single_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1506e9",
   "metadata": {},
   "source": [
    "## SpecAugment Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SpecAugment\n",
    "import importlib\n",
    "from utils.specaugment import get_recommended_params, visualize_specaugment\n",
    "from utils.util import fast_single_fold_training_with_augmentation\n",
    "\n",
    "# Reload modules\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommended SpecAugment parameters for your dataset\n",
    "total_samples = len(metadata_df)\n",
    "num_classes_actual = len(set(labels_list))\n",
    "\n",
    "recommended_params = get_recommended_params(\n",
    "    num_samples=total_samples,\n",
    "    num_classes=num_classes_actual,\n",
    "    input_size=(224, 313)\n",
    ")\n",
    "\n",
    "print(f\"Dataset statistics:\")\n",
    "print(f\"  Total samples: {total_samples}\")\n",
    "print(f\"  Number of classes: {num_classes_actual}\")\n",
    "print(f\"  Samples per class (avg): {total_samples / num_classes_actual:.1f}\")\n",
    "\n",
    "print(f\"\\nRecommended SpecAugment parameters:\")\n",
    "for key, value in recommended_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SpecAugment visualization on actual data\n",
    "print(\"Testing SpecAugment on actual training data...\")\n",
    "\n",
    "# Get a sample from the dataset\n",
    "sample_idx = 0\n",
    "sample_spec, sample_label = dataset[sample_idx]\n",
    "\n",
    "print(f\"Sample shape: {sample_spec.shape}\")\n",
    "print(f\"Sample label: {sample_label}\")\n",
    "\n",
    "# Apply SpecAugment\n",
    "from utils.specaugment import SpecAugment\n",
    "augmenter = SpecAugment(**recommended_params)\n",
    "augmented_spec = augmenter(sample_spec)\n",
    "\n",
    "# Visualize\n",
    "visualize_specaugment(\n",
    "    sample_spec.squeeze(0),  # Remove channel dimension for visualization\n",
    "    augmented_spec.squeeze(0),\n",
    "    title=f\"SpecAugment on Training Data - Class {sample_label}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BirdCNN with SpecAugment using predefined author-grouped splits\n",
    "print(\"Training BirdCNN with SpecAugment and author-grouped splits...\")\n",
    "\n",
    "# Use the same train/val indices from earlier\n",
    "train_indices, val_indices = train_indices_single, val_indices_single\n",
    "\n",
    "# Train with SpecAugment\n",
    "results_with_augment = fast_single_fold_training_with_augmentation(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=250,\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True,\n",
    "    augment_params=recommended_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf98d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves with SpecAugment\n",
    "util.plot_single_fold_curve(results_with_augment, metric_key='accuracies', title=\"SpecAugment - Accuracy Curves\", ylabel=\"Accuracy\")\n",
    "util.plot_single_fold_curve(results_with_augment, metric_key='losses', title=\"SpecAugment - Loss Curves\", ylabel=\"Cross Entropy Loss\")\n",
    "util.plot_single_fold_curve(results_with_augment, metric_key='f1s', title=\"SpecAugment - F1 Score Curves\", ylabel=\"Macro F1 Score\")\n",
    "\n",
    "# Print results\n",
    "util.print_single_fold_results(results_with_augment)\n",
    "\n",
    "# Display confusion matrix\n",
    "util.plot_confusion_matrix(results_with_augment['confusion_matrix'], title=\"BirdCNN with SpecAugment - Validation Confusion Matrix\")\n",
    "util.print_confusion_matrix_stats(results_with_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75feab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results: Original vs SpecAugment\n",
    "print(\"COMPARISON: Original vs SpecAugment Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'single_results' in locals():\n",
    "    print(\"Original Training (without SpecAugment):\")\n",
    "    print(f\"  Final Val Accuracy: {single_results['final_val_acc']:.4f}\")\n",
    "    print(f\"  Final Val F1 Score: {single_results['final_val_f1']:.4f}\")\n",
    "    print(f\"  Best Val Accuracy: {single_results['best_val_acc']:.4f}\")\n",
    "    print(f\"  Best Val F1 Score: {single_results['best_val_f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nWith SpecAugment:\")\n",
    "    print(f\"  Final Val Accuracy: {results_with_augment['final_val_acc']:.4f}\")\n",
    "    print(f\"  Final Val F1 Score: {results_with_augment['final_val_f1']:.4f}\")\n",
    "    print(f\"  Best Val Accuracy: {results_with_augment['best_val_acc']:.4f}\")\n",
    "    print(f\"  Best Val F1 Score: {results_with_augment['best_val_f1']:.4f}\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    acc_improvement = results_with_augment['final_val_acc'] - single_results['final_val_acc']\n",
    "    f1_improvement = results_with_augment['final_val_f1'] - single_results['final_val_f1']\n",
    "    \n",
    "    print(f\"\\nImprovement with SpecAugment:\")\n",
    "    print(f\"  Accuracy: {acc_improvement:+.4f}\")\n",
    "    print(f\"  F1 Score: {f1_improvement:+.4f}\")\n",
    "else:\n",
    "    print(\"Run the original training first to compare results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom SpecAugment parameters experiment\n",
    "print(\"Experimenting with more aggressive SpecAugment parameters...\")\n",
    "\n",
    "# More aggressive parameters for experimentation\n",
    "aggressive_params = {\n",
    "    'time_mask_param': 60,  # Larger time masks\n",
    "    'freq_mask_param': 20,  # Larger frequency masks\n",
    "    'num_time_masks': 2,    # Multiple time masks\n",
    "    'num_freq_masks': 1,\n",
    "    'mask_value': 0.0,\n",
    "    'p': 0.9               # Higher probability\n",
    "}\n",
    "\n",
    "print(f\"Aggressive SpecAugment parameters: {aggressive_params}\")\n",
    "\n",
    "# Train with aggressive parameters\n",
    "results_aggressive = fast_single_fold_training_with_augmentation(\n",
    "    dataset=dataset,\n",
    "    train_indices=train_indices,\n",
    "    val_indices=val_indices,\n",
    "    model_class=models.BirdCNN,\n",
    "    num_classes=len(set(labels_list)),\n",
    "    num_epochs=200,  # Shorter training for experimentation\n",
    "    batch_size=48,\n",
    "    lr=0.001,\n",
    "    use_class_weights=True,\n",
    "    estop=35,\n",
    "    standardize=True,\n",
    "    augment_params=aggressive_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all SpecAugment variants\n",
    "print(\"COMPARISON: Recommended vs Aggressive SpecAugment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Recommended SpecAugment:\")\n",
    "print(f\"  Final Val Accuracy: {results_with_augment['final_val_acc']:.4f}\")\n",
    "print(f\"  Final Val F1 Score: {results_with_augment['final_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nAggressive SpecAugment:\")\n",
    "print(f\"  Final Val Accuracy: {results_aggressive['final_val_acc']:.4f}\")\n",
    "print(f\"  Final Val F1 Score: {results_aggressive['final_val_f1']:.4f}\")\n",
    "\n",
    "# Determine which is better\n",
    "if results_aggressive['final_val_f1'] > results_with_augment['final_val_f1']:\n",
    "    print(f\"\\n✓ Aggressive parameters perform better!\")\n",
    "    best_augment_results = results_aggressive\n",
    "    best_params = aggressive_params\n",
    "else:\n",
    "    print(f\"\\n✓ Recommended parameters perform better!\")\n",
    "    best_augment_results = results_with_augment\n",
    "    best_params = recommended_params\n",
    "\n",
    "print(f\"Best SpecAugment parameters: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
