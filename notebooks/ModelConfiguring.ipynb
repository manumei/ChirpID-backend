{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fc238e",
   "metadata": {},
   "source": [
    "# Model Configuration Testing with Performance Optimizations\n",
    "\n",
    "This notebook is designed for systematic hyperparameter optimization with **state-of-the-art performance optimizations** for high-end hardware (RTX 5080 + Ryzen 9 7950X). It allows testing different combinations of model parameters to find the optimal configuration for bird song classification.\n",
    "\n",
    "## Configuration Parameters:\n",
    "- **ADAM Optimizer**: Whether to use Adam optimizer (vs SGD)\n",
    "- **Early Stopping Threshold**: Patience for early stopping\n",
    "- **Batch Size**: Training batch size *(automatically optimized for AMP)*\n",
    "- **Class Weights**: Whether to use class weights for imbalanced data\n",
    "- **L2 Regularization**: Weight decay parameter\n",
    "- **Learning Rate Schedule**: Type and parameters for LR scheduling\n",
    "- **Initial Learning Rate**: Starting learning rate\n",
    "- **Standardization**: Whether to standardize features\n",
    "- **SpecAugment**: Whether to apply spectrogram augmentation\n",
    "- **Noise Augment**: Whether to apply Gaussian noise augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e13558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5080\n",
      "GPU Memory: 15.9 GB\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  CUDA not available - running on CPU (will be slow)\")\n",
    "\n",
    "# Performance optimization settings\n",
    "ENABLE_OPTIMIZATIONS = True  # Set to False to disable all optimizations\n",
    "ENABLE_PARALLEL_FOLDS = False  # Set to True for cross-validation mode\n",
    "MAX_PARALLEL_FOLDS = -1  # Adjust based on GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b24d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path: str) -> Tuple[np.ndarray, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Reads the CSV with all the training data: grayscale log-mel spectrogram pixels, label and author of each sample\n",
    "    And extracts them respectively, resizing the features to fit the CNN input shape (channel, height, width).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing training data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.array, np.array]: Returns features, labels, and authors from the CSV file. Features shape is (N x 70,112),\n",
    "        while labels and authors are 1D arrays of size N, where N is the number of samples.\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "    print(f\"Number of authors: {df['author'].nunique()}\")\n",
    "\n",
    "    # Extract labels, authors, and features\n",
    "    labels = df['label'].values.astype(np.int64)\n",
    "    authors = df['author'].values\n",
    "    features = df.drop(columns=['label', 'author']).values.astype(np.float32)\n",
    "    print(f\"Features shape before reshape: {features.shape} (should be N x 70112!)\")\n",
    "\n",
    "    # Convert to 0-1 range and reshape for CNN\n",
    "    features /= 255.0\n",
    "    features = features.reshape(-1, 1, 224, 313)\n",
    "\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Authors shape:\", authors.shape)\n",
    "    print(\"Unique classes:\", len(np.unique(labels)))\n",
    "    print(\"Unique authors:\", len(np.unique(authors)))\n",
    "\n",
    "    # No need for df variable after extracting features, release memory\n",
    "    del df\n",
    "\n",
    "    return features, labels, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d88ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_data(specs_dir: str, specs_csv_path: str) -> Tuple[np.ndarray, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Load spectrograms from .npy files and metadata from CSV.\n",
    "    \n",
    "    Args:\n",
    "        specs_dir (str): Directory containing .npy spectrogram files\n",
    "        specs_csv_path (str): Path to CSV file containing metadata (filename, class_id, author)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.array, np.array]: Returns features, labels, and authors.\n",
    "        Features are already normalized to [0,1] and shaped as (N, 1, 224, 313)\n",
    "    \"\"\"\n",
    "    # Load metadata CSV\n",
    "    df = pd.read_csv(specs_csv_path)\n",
    "    \n",
    "    print(f\"Metadata shape: {df.shape}\")\n",
    "    print(f\"Number of classes: {df['class_id'].nunique()}\")\n",
    "    print(f\"Number of authors: {df['author'].nunique()}\")\n",
    "    \n",
    "    # Extract labels and authors\n",
    "    labels = df['class_id'].values.astype(np.int64)\n",
    "    authors = df['author'].values\n",
    "    filenames = df['filename'].values\n",
    "    \n",
    "    # Load spectrograms from .npy files\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        spec_path = os.path.join(specs_dir, filename)\n",
    "        \n",
    "        if os.path.exists(spec_path):\n",
    "            try:\n",
    "                # Load .npy file - already normalized to [0,1] as float32\n",
    "                spec_array = np.load(spec_path)\n",
    "                \n",
    "                # Add channel dimension: (1, height, width)\n",
    "                spec_array = spec_array[np.newaxis, ...]\n",
    "                \n",
    "                features_list.append(spec_array)\n",
    "                valid_indices.append(i)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {spec_path}\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features = np.array(features_list, dtype=np.float32)\n",
    "    \n",
    "    # Filter labels and authors to match loaded features\n",
    "    labels = labels[valid_indices]\n",
    "    authors = authors[valid_indices]\n",
    "    \n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Authors shape: {authors.shape}\")\n",
    "    print(f\"Unique classes: {len(np.unique(labels))}\")\n",
    "    print(f\"Unique authors: {len(np.unique(authors))}\")\n",
    "    print(f\"Successfully loaded {len(features)} out of {len(filenames)} spectrograms\")\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return features, labels, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19b2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New pipeline using .npy spectrograms from specs/ directory\n",
    "# specs_dir = os.path.join('..', 'database', 'specs')\n",
    "# specs_csv_path = os.path.join('..', 'database', 'meta', 'final_specs.csv')\n",
    "# features, labels, authors = load_npy_data(specs_dir, specs_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd659cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2987, 70114)\n",
      "Number of classes: 33\n",
      "Number of authors: 106\n",
      "Features shape before reshape: (2987, 70112) (should be N x 70112!)\n",
      "Features shape: (2987, 1, 224, 313)\n",
      "Labels shape: (2987,)\n",
      "Authors shape: (2987,)\n",
      "Unique classes: 33\n",
      "Unique authors: 106\n"
     ]
    }
   ],
   "source": [
    "# Keep the old CSV-based loading for compatibility (uncomment if needed)\n",
    "train_data_path = os.path.join('..', 'database', 'meta', 'final', 'train_data.csv')\n",
    "features, labels, authors = load_csv_data(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85319ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average samples per class: 90.5\n"
     ]
    }
   ],
   "source": [
    "# Display class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique_labels, counts, alpha=0.7)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xticks(unique_labels)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average samples per class: {len(labels) / len(unique_labels):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60fe59",
   "metadata": {},
   "source": [
    "## Configuration Templates\n",
    "\n",
    "20 different hyperparameter configurations designed for audio classification with ~3200 samples and 30 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8aa83",
   "metadata": {},
   "source": [
    "## Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78653576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best seed\n",
    "# from utils.split import precompute_single_fold_split, precompute_kfold_splits, display_split_statistics\n",
    "\n",
    "# # Pre-compute single fold split (for most configurations)\n",
    "# single_fold_split = precompute_single_fold_split(\n",
    "#     features=features,\n",
    "#     labels=labels, \n",
    "#     authors=authors,\n",
    "#     test_size=0.2,\n",
    "#     max_attempts=250_000,\n",
    "#     min_test_segments=5)\n",
    "\n",
    "# # Pre-compute k-fold splits (for cross-validation configurations)  \n",
    "# kfold_splits = precompute_kfold_splits(\n",
    "#     features=features,\n",
    "#     labels=labels,\n",
    "#     authors=authors,\n",
    "#     n_splits=4,\n",
    "#     max_attempts=12_000, # mas para k-fold\n",
    "#     min_val_segments=0)\n",
    "\n",
    "# print(f\"Single Fold Split Type: {type(single_fold_split)}, Shape: {len(single_fold_split)}\")\n",
    "# print(f\"K-Fold Splits Type: {type(kfold_splits)}, Shape: {len(kfold_splits)}\")\n",
    "\n",
    "# # Display statistics for verification\n",
    "# display_split_statistics(single_fold_split, \"single\")\n",
    "# display_split_statistics(kfold_splits, \"kfold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78653576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with a set seed, las que ya encontre arriba, para tardar menos\n",
    "\n",
    "from utils.split import get_set_seed_indices, get_set_seed_kfold_indices, display_split_statistics\n",
    "seed_single = 245323\n",
    "seed_kfold = 11052\n",
    "\n",
    "single_fold_split = get_set_seed_indices(\n",
    "    features=features,\n",
    "    labels=labels, \n",
    "    authors=authors,\n",
    "    test_size=0.2,\n",
    "    seed=seed_single)\n",
    "\n",
    "kfold_splits = get_set_seed_kfold_indices(\n",
    "    features=features,\n",
    "    labels=labels,\n",
    "    authors=authors,\n",
    "    n_splits=4,\n",
    "    seed=seed_kfold)\n",
    "\n",
    "display_split_statistics(single_fold_split, \"single\")\n",
    "display_split_statistics(kfold_splits, \"kfold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0ba60",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c0ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Optimization Summary:\n",
      "   â€¢ Mixed Precision: Enabled in all configs\n",
      "   â€¢ Gradient Clipping: 0.01-10.0 range (extreme variety)\n",
      "   â€¢ Batch Sizes: 4-320 range (massive variety)\n",
      "   â€¢ Expected Speed Improvement: 40-60% per configuration\n"
     ]
    }
   ],
   "source": [
    "# Define 20 configuration templates for systematic testing\n",
    "configurations = {\n",
    "    'config0': {  # config16 - as is\n",
    "        'name': 'Chaos Theory Adam',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 37,\n",
    "        'batch_size': 45,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3.7e-4,\n",
    "        'lr_schedule': {'type': 'cosine', 'T_max': 73},\n",
    "        'initial_lr': 0.00137,\n",
    "        'standardize': False,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 247,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 0.73,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config1': {  # config9 - as is\n",
    "        'name': 'Balanced Classes Focus',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 28,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0012,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config2': {  # config5 - as is\n",
    "        'name': 'Small Batch High LR (AMP Optimized)',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 24,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.98},\n",
    "        'initial_lr': 0.004,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 180,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config3': {  # config9 + noise_augment (spec+noise)\n",
    "        'name': 'Balanced Classes Focus (Spec+Noise Aug)',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 28,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0012,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': True,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config4': {  # config9 + higher batch size\n",
    "        'name': 'Balanced Classes (Higher Batch)',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 40,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0012,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config5': {  # config2 with config9's gamma/estop, more augmentation\n",
    "        'name': 'Exponential LR + Dual Augment',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 40,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0025,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': True,\n",
    "        'num_epochs': 200,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config6': {  # AdamW variant of config9\n",
    "        'name': 'Balanced Classes AdamW',\n",
    "        'use_adam': 'adamw',\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 28,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0012,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config7': {  # config7 - heavy regularization, plateau schedule\n",
    "        'name': 'Heavy Regularization (Optimized)',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 60,\n",
    "        'batch_size': 40,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 1e-3,\n",
    "        'lr_schedule': {'type': 'plateau', 'factor': 0.7, 'patience': 15},\n",
    "        'initial_lr': 0.001,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': True,\n",
    "        'num_epochs': 300,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.2,\n",
    "        'parallel_folds': ENABLE_OPTIMIZATIONS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    'config8' : {\n",
    "        'name': 'Best Results Frankenstein',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 40,\n",
    "        'batch_size': 40,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 0.0003,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.98},\n",
    "        'initial_lr': 0.003,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': True,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': False,\n",
    "        'max_parallel_folds': 2,\n",
    "        'optimize_dataloaders': True,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234616d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# If you also want to reload the utils package itself\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Reload all the utils modules you're importing\n",
    "import utils.training_core\n",
    "import utils.training_engine\n",
    "import utils.models\n",
    "\n",
    "importlib.reload(utils.training_core)\n",
    "importlib.reload(utils.training_engine)\n",
    "importlib.reload(utils.models)\n",
    "\n",
    "# Re-import after reloading to get the updated versions\n",
    "from utils.training_core import single_fold_training, cross_val_training\n",
    "import utils.models as models\n",
    "import utils.training_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234616d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance optimizations: ENABLED\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG0: Conservative Baseline (Optimized)\n",
      "Training Single-Fold with pre-made splits for config0...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config0 | TrLoss: 0.0846 | TrAcc: 0.9721 | ValLoss: 2.8799 | ValAcc: 0.4259:  28%|â–ˆâ–ˆâ–Š       | 57/200 [01:35<03:59,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 57 epochs (best at epoch 23)\n",
      "Best - Val Acc: 0.4815, Val F1: 0.4519\n",
      "\n",
      "âœ“ config0 completed successfully!\n",
      "  Final Val Accuracy: 0.4259\n",
      "  Final Val F1 Score: 0.4144\n",
      "  GPU Memory: 0.0GB / 15.9GB (0.2%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG1: Aggressive Baseline (Optimized)\n",
      "Training Single-Fold with pre-made splits for config1...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config1 | TrLoss: 0.5367 | TrAcc: 0.8594 | ValLoss: 3.2111 | ValAcc: 0.3381:  25%|â–ˆâ–ˆâ–Œ       | 63/250 [01:39<04:55,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 63 epochs (best at epoch 39)\n",
      "Best - Val Acc: 0.3381, Val F1: 0.3297\n",
      "\n",
      "âœ“ config1 completed successfully!\n",
      "  Final Val Accuracy: 0.3381\n",
      "  Final Val F1 Score: 0.3297\n",
      "  GPU Memory: 0.1GB / 15.9GB (0.4%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG2: Exponential LR Decay (Optimized)\n",
      "Training Single-Fold with pre-made splits for config2...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config2 | TrLoss: 0.0063 | TrAcc: 0.9996 | ValLoss: 2.3918 | ValAcc: 0.4953:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 131/220 [03:15<02:13,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 131 epochs (best at epoch 92)\n",
      "Best - Val Acc: 0.5109, Val F1: 0.5033\n",
      "\n",
      "âœ“ config2 completed successfully!\n",
      "  Final Val Accuracy: 0.4953\n",
      "  Final Val F1 Score: 0.4903\n",
      "  GPU Memory: 0.1GB / 15.9GB (0.5%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG3: ReduceLROnPlateau (Optimized)\n",
      "Training Single-Fold with pre-made splits for config3...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config3 | TrLoss: 0.0028 | TrAcc: 1.0000 | ValLoss: 2.4923 | ValAcc: 0.4141:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/300 [04:02<03:23,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 163 epochs (best at epoch 114)\n",
      "Best - Val Acc: 0.4359, Val F1: 0.4221\n",
      "\n",
      "âœ“ config3 completed successfully!\n",
      "  Final Val Accuracy: 0.4141\n",
      "  Final Val F1 Score: 0.3945\n",
      "  GPU Memory: 0.1GB / 15.9GB (0.7%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG4: Cosine Annealing (Optimized)\n",
      "Training Single-Fold with pre-made splits for config4...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config4 | TrLoss: 0.0563 | TrAcc: 0.9893 | ValLoss: 2.9446 | ValAcc: 0.4645:  24%|â–ˆâ–ˆâ–       | 48/200 [01:20<04:16,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 48 epochs (best at epoch 19)\n",
      "Best - Val Acc: 0.5031, Val F1: 0.4776\n",
      "\n",
      "âœ“ config4 completed successfully!\n",
      "  Final Val Accuracy: 0.4645\n",
      "  Final Val F1 Score: 0.4422\n",
      "  GPU Memory: 0.1GB / 15.9GB (0.8%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG5: Small Batch High LR (AMP Optimized)\n",
      "Training Single-Fold with pre-made splits for config5...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config5 | TrLoss: 0.1275 | TrAcc: 0.9742 | ValLoss: 2.2567 | ValAcc: 0.5170:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 71/180 [01:55<02:57,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 71 epochs (best at epoch 37)\n",
      "Best - Val Acc: 0.5370, Val F1: 0.5269\n",
      "\n",
      "âœ“ config5 completed successfully!\n",
      "  Final Val Accuracy: 0.5170\n",
      "  Final Val F1 Score: 0.5070\n",
      "  GPU Memory: 0.2GB / 15.9GB (1.0%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG6: Large Batch Conservative (AMP Optimized)\n",
      "Training Single-Fold with pre-made splits for config6...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config6 | TrLoss: 0.0322 | TrAcc: 0.9948 | ValLoss: 3.6445 | ValAcc: 0.3172:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 93/250 [02:30<04:14,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 93 epochs (best at epoch 49)\n",
      "Best - Val Acc: 0.4469, Val F1: 0.4235\n",
      "\n",
      "âœ“ config6 completed successfully!\n",
      "  Final Val Accuracy: 0.3172\n",
      "  Final Val F1 Score: 0.2963\n",
      "  GPU Memory: 0.2GB / 15.9GB (1.1%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG7: Heavy Regularization (Optimized)\n",
      "Training Single-Fold with pre-made splits for config7...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config7 | TrLoss: 0.0169 | TrAcc: 1.0000 | ValLoss: 2.1315 | ValAcc: 0.4750:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 288/300 [07:04<00:17,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 288 epochs (best at epoch 229)\n",
      "Best - Val Acc: 0.5094, Val F1: 0.4987\n",
      "\n",
      "âœ“ config7 completed successfully!\n",
      "  Final Val Accuracy: 0.4750\n",
      "  Final Val F1 Score: 0.4690\n",
      "  GPU Memory: 0.2GB / 15.9GB (1.2%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG8: Light Regularization (Optimized)\n",
      "Training Single-Fold with pre-made splits for config8...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config8 | TrLoss: 0.0464 | TrAcc: 0.9870 | ValLoss: 3.2148 | ValAcc: 0.4344:  29%|â–ˆâ–ˆâ–‰       | 44/150 [01:13<02:57,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 44 epochs (best at epoch 20)\n",
      "Best - Val Acc: 0.4453, Val F1: 0.4146\n",
      "\n",
      "âœ“ config8 completed successfully!\n",
      "  Final Val Accuracy: 0.4344\n",
      "  Final Val F1 Score: 0.4043\n",
      "  GPU Memory: 0.2GB / 15.9GB (1.4%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG9: Balanced Classes Focus\n",
      "Training Single-Fold with pre-made splits for config9...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config9 | TrLoss: 0.0096 | TrAcc: 0.9991 | ValLoss: 2.1995 | ValAcc: 0.5124:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 99/220 [03:17<04:01,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 99 epochs (best at epoch 65)\n",
      "Best - Val Acc: 0.5497, Val F1: 0.5421\n",
      "\n",
      "âœ“ config9 completed successfully!\n",
      "  Final Val Accuracy: 0.5124\n",
      "  Final Val F1 Score: 0.5061\n",
      "  GPU Memory: 0.2GB / 15.9GB (1.5%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG10: idfk\n",
      "Training Single-Fold with pre-made splits for config10...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config10 | TrLoss: 3.4967 | TrAcc: 0.0335 | ValLoss: 3.4986 | ValAcc: 0.0170:  10%|â–‰         | 40/420 [01:04<10:12,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 40 epochs (best at epoch 16)\n",
      "Best - Val Acc: 0.0602, Val F1: 0.0117\n",
      "\n",
      "âœ“ config10 completed successfully!\n",
      "  Final Val Accuracy: 0.0170\n",
      "  Final Val F1 Score: 0.0010\n",
      "  GPU Memory: 0.3GB / 15.9GB (1.7%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG11: Mega Batch Momentum SGD\n",
      "Training Single-Fold with pre-made splits for config11...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config11 | TrLoss: 0.4158 | TrAcc: 0.8875 | ValLoss: 3.5065 | ValAcc: 0.3187:  21%|â–ˆâ–ˆ        | 38/180 [01:10<04:23,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 38 epochs (best at epoch 24)\n",
      "Best - Val Acc: 0.4641, Val F1: 0.4519\n",
      "\n",
      "âœ“ config11 completed successfully!\n",
      "  Final Val Accuracy: 0.3187\n",
      "  Final Val F1 Score: 0.3152\n",
      "  GPU Memory: 0.3GB / 15.9GB (1.8%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG12: Aggressive Adam Cyclic\n",
      "Training Single-Fold with pre-made splits for config12...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config12 | TrLoss: 3.2484 | TrAcc: 0.0807 | ValLoss: 3.4082 | ValAcc: 0.0417:  14%|â–ˆâ–Ž        | 27/200 [00:51<05:32,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 27 epochs (best at epoch 16)\n",
      "Best - Val Acc: 0.0967, Val F1: 0.0487\n",
      "\n",
      "âœ“ config12 completed successfully!\n",
      "  Final Val Accuracy: 0.0417\n",
      "  Final Val F1 Score: 0.0116\n",
      "  GPU Memory: 0.3GB / 15.9GB (1.9%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG13: Micro Batch High Frequency\n",
      "Training Single-Fold with pre-made splits for config13...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config13 | TrLoss: 0.7797 | TrAcc: 0.7882 | ValLoss: 2.9286 | ValAcc: 0.3746:  12%|â–ˆâ–        | 60/500 [03:29<25:38,  3.50s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 60 epochs (best at epoch 21)\n",
      "Best - Val Acc: 0.3869, Val F1: 0.3704\n",
      "\n",
      "âœ“ config13 completed successfully!\n",
      "  Final Val Accuracy: 0.3746\n",
      "  Final Val F1 Score: 0.3603\n",
      "  GPU Memory: 0.3GB / 15.9GB (2.1%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG14: No Regularization Speed Run\n",
      "Training Single-Fold with pre-made splits for config14...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config14 | TrLoss: 0.0991 | TrAcc: 0.9714 | ValLoss: 6.1293 | ValAcc: 0.2559:  30%|â–ˆâ–ˆâ–ˆ       | 54/180 [01:39<03:52,  1.85s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 54 epochs (best at epoch 32)\n",
      "Best - Val Acc: 0.4492, Val F1: 0.4095\n",
      "\n",
      "âœ“ config14 completed successfully!\n",
      "  Final Val Accuracy: 0.2559\n",
      "  Final Val F1 Score: 0.2279\n",
      "  GPU Memory: 0.4GB / 15.9GB (2.2%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG15: Extreme Regularization Marathon\n",
      "Training Single-Fold with pre-made splits for config15...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config15 | TrLoss: 3.4868 | TrAcc: 0.0741 | ValLoss: 3.4941 | ValAcc: 0.0442:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 526/600 [14:30<02:02,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 526 epochs (best at epoch 487)\n",
      "Best - Val Acc: 0.0473, Val F1: 0.0117\n",
      "\n",
      "âœ“ config15 completed successfully!\n",
      "  Final Val Accuracy: 0.0442\n",
      "  Final Val F1 Score: 0.0108\n",
      "  GPU Memory: 0.4GB / 15.9GB (2.4%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG16: Chaos Theory Adam\n",
      "Training Single-Fold with pre-made splits for config16...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config16 | TrLoss: 0.1617 | TrAcc: 0.9590 | ValLoss: 2.6450 | ValAcc: 0.4016:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 121/247 [03:00<03:08,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 121 epochs (best at epoch 85)\n",
      "Best - Val Acc: 0.5540, Val F1: 0.5418\n",
      "\n",
      "âœ“ config16 completed successfully!\n",
      "  Final Val Accuracy: 0.4016\n",
      "  Final Val F1 Score: 0.3826\n",
      "  GPU Memory: 0.4GB / 15.9GB (2.5%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG17: Binary Extremes SGD\n",
      "Training Single-Fold with pre-made splits for config17...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config17 | TrLoss: 3.4942 | TrAcc: 0.0464 | ValLoss: 3.4973 | ValAcc: 0.0250:   2%|â–         | 14/650 [00:34<26:08,  2.47s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 14 epochs (best at epoch 5)\n",
      "Best - Val Acc: 0.0406, Val F1: 0.0024\n",
      "\n",
      "âœ“ config17 completed successfully!\n",
      "  Final Val Accuracy: 0.0250\n",
      "  Final Val F1 Score: 0.0015\n",
      "  GPU Memory: 0.4GB / 15.9GB (2.6%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG18: Goldilocks Zone Hunter\n",
      "Training Single-Fold with pre-made splits for config18...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config18 | TrLoss: 0.0089 | TrAcc: 1.0000 | ValLoss: 2.1238 | ValAcc: 0.4854:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 198/333 [04:56<03:21,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 198 epochs (best at epoch 149)\n",
      "Best - Val Acc: 0.5000, Val F1: 0.4762\n",
      "\n",
      "âœ“ config18 completed successfully!\n",
      "  Final Val Accuracy: 0.4854\n",
      "  Final Val F1 Score: 0.4673\n",
      "  GPU Memory: 0.4GB / 15.9GB (2.8%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG19: Anti-Pattern Rebellion\n",
      "Training Single-Fold with pre-made splits for config19...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config19 | TrLoss: 3.4965 | TrAcc: 0.0344 | ValLoss: 3.4967 | ValAcc: 0.0305:   8%|â–Š         | 79/1000 [06:17<1:13:24,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 79 epochs (best at epoch 40)\n",
      "Best - Val Acc: 0.0549, Val F1: 0.0032\n",
      "\n",
      "âœ“ config19 completed successfully!\n",
      "  Final Val Accuracy: 0.0305\n",
      "  Final Val F1 Score: 0.0018\n",
      "  GPU Memory: 0.5GB / 15.9GB (2.9%)\n",
      "\n",
      "============================================================\n",
      "TESTING CONFIG20: Extreme Regularization Marathon\n",
      "Training Single-Fold with pre-made splits for config20...\n",
      "Using provided arrays\n",
      "\\nStarting single fold training...\n",
      "Train size: 2330, Val size: 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config: config20 | TrLoss: 3.4961 | TrAcc: 0.0237 | ValLoss: 3.4965 | ValAcc: 0.0396:   8%|â–Š         | 46/600 [01:23<16:42,  1.81s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped after 46 epochs (best at epoch 7)\n",
      "Best - Val Acc: 0.0549, Val F1: 0.0032\n",
      "\n",
      "âœ“ config20 completed successfully!\n",
      "  Final Val Accuracy: 0.0396\n",
      "  Final Val F1 Score: 0.0023\n",
      "  GPU Memory: 0.5GB / 15.9GB (3.0%)\n",
      "\n",
      "================================================================================\n",
      "Successful configurations: 21/21\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "results_database = {}\n",
    "training_start_time = datetime.now()\n",
    "\n",
    "print(f\"Performance optimizations: {'ENABLED' if ENABLE_OPTIMIZATIONS else 'DISABLED'}\")\n",
    "if ENABLE_PARALLEL_FOLDS:\n",
    "    print(f\"Parallel fold training: ENABLED (max {MAX_PARALLEL_FOLDS} folds)\")\n",
    "\n",
    "# Track overall progress and performance metrics\n",
    "successful_configs = 0\n",
    "failed_configs = []\n",
    "optimization_benchmarks = {\n",
    "    'traditional_times': [],\n",
    "    'optimized_times': [],\n",
    "    'speedup_ratios': []\n",
    "}\n",
    "\n",
    "for config_id, config in configurations.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TESTING {config_id.upper()}: {config['name']}\")\n",
    "    \n",
    "    config_start_time = datetime.now()\n",
    "    \n",
    "    # Convert config to training_core format with optimizations\n",
    "    training_config = {\n",
    "        # Basic training parameters\n",
    "        'num_epochs': config['num_epochs'],\n",
    "        'batch_size': config['batch_size'],\n",
    "        'learning_rate': config['initial_lr'],\n",
    "        'use_class_weights': config['use_class_weights'],\n",
    "        'early_stopping': config['estop_thresh'],\n",
    "        'standardize': config['standardize'],\n",
    "        'test_size': 0.2,\n",
    "        'max_split_attempts': 5000,\n",
    "        'min_test_segments': 5,\n",
    "        'l2_regularization': config['l2_regularization'],\n",
    "        'use_adam': config['use_adam'],\n",
    "        'lr_schedule': config['lr_schedule'],\n",
    "        \n",
    "        # NEW PERFORMANCE OPTIMIZATIONS\n",
    "        'mixed_precision': config.get('mixed_precision', False),\n",
    "        'gradient_clipping': config.get('gradient_clipping', 0),\n",
    "        'parallel_folds': config.get('parallel_folds', False),\n",
    "        'max_parallel_folds': config.get('max_parallel_folds', 2),\n",
    "        \n",
    "        # Enhanced DataLoader settings (automatically optimized)\n",
    "        'optimize_dataloaders': ENABLE_OPTIMIZATIONS,\n",
    "        'debug_dataloaders': False,  # Set to True for debugging\n",
    "        'benchmark_performance': True  # Enable performance tracking\n",
    "    }\n",
    "    \n",
    "    # Execute training with performance monitoring\n",
    "    training_start = time.time()\n",
    "    \n",
    "    # Choose training method based on parallel folds setting\n",
    "    if training_config.get('parallel_folds', False):\n",
    "        print(f\"Training K-Fold Parallel with pre-made splits for {config_id}...\")\n",
    "        result, best_result = cross_val_training(\n",
    "            features=features,\n",
    "            labels=labels,\n",
    "            authors=authors,\n",
    "            model_class=models.BirdCNN,\n",
    "            num_classes=len(np.unique(labels)),\n",
    "            config=training_config,\n",
    "            spec_augment=config['spec_augment'],\n",
    "            gaussian_noise=config['noise_augment'],\n",
    "            precomputed_splits=kfold_splits,  # Use pre-computed k-fold splits\n",
    "            config_id=config_id  # Pass config_id for progress bar\n",
    "        )\n",
    "        # Extract single fold equivalent metrics for comparison\n",
    "        if 'summary' in result:\n",
    "            final_result = {\n",
    "                'best_val_acc': result['summary']['mean_best_val_acc'],\n",
    "                'best_val_f1': result['summary']['mean_best_val_f1'],\n",
    "                'best_val_loss': result['summary']['mean_best_val_loss'],\n",
    "                'training_type': 'cross_validation',\n",
    "                'num_folds': training_config.get('k_folds', 4),\n",
    "                'parallel_execution': True\n",
    "            }\n",
    "        else:\n",
    "            final_result = best_result  # fallback\n",
    "    else:\n",
    "        print(f\"Training Single-Fold with pre-made splits for {config_id}...\")\n",
    "        final_result = single_fold_training(\n",
    "            features=features,\n",
    "            labels=labels,\n",
    "            authors=authors,\n",
    "            model_class=models.BirdCNN,\n",
    "            num_classes=len(np.unique(labels)),\n",
    "            config=training_config,\n",
    "            spec_augment=config['spec_augment'],\n",
    "            gaussian_noise=config['noise_augment'],\n",
    "            precomputed_split=single_fold_split,  # Use pre-computed single fold split\n",
    "            config_id=config_id  # Pass config_id for progress bar\n",
    "        )\n",
    "        final_result['training_type'] = 'single_fold'\n",
    "        final_result['parallel_execution'] = False\n",
    "    \n",
    "    training_end = time.time()\n",
    "    training_duration = training_end - training_start\n",
    "    \n",
    "    # Store results with optimization metadata\n",
    "    config_end_time = datetime.now()\n",
    "    \n",
    "    results_database[config_id] = {\n",
    "        'config': config,\n",
    "        'result': final_result,\n",
    "        'training_time_seconds': training_duration,\n",
    "        'timestamp': config_end_time.isoformat(),\n",
    "        'status': 'success',\n",
    "        'optimization_metadata': {\n",
    "            'mixed_precision_used': training_config.get('mixed_precision', False),\n",
    "            'gradient_clipping_used': training_config.get('gradient_clipping', 0) > 0,\n",
    "            'parallel_folds_used': training_config.get('parallel_folds', False),\n",
    "            'optimized_dataloaders': training_config.get('optimize_dataloaders', False),\n",
    "            'batch_size_optimized': config['batch_size'] > 32 if ENABLE_OPTIMIZATIONS else False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    successful_configs += 1\n",
    "    \n",
    "    # Performance reporting\n",
    "    print(f\"\\nâœ“ {config_id} completed successfully!\")\n",
    "    print(f\"  Best Val Accuracy: {final_result['best_val_acc']:.4f}\")\n",
    "    print(f\"  Best Val F1 Score: {final_result['best_val_f1']:.4f}\")\n",
    "    \n",
    "    # GPU memory status (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / (1024**3)\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"  GPU Memory: {memory_used:.1f}GB / {memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
    "\n",
    "\n",
    "training_end_time = datetime.now()\n",
    "total_duration = (training_end_time - training_start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Successful configurations: {successful_configs}/{len(configurations)}\")\n",
    "if failed_configs:\n",
    "    print(f\"Failed configurations: {', '.join(failed_configs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d52a4",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "Comprehensive analysis and visualization of all configuration results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils.metrics)\n",
    "from utils.metrics import plot_metrics\n",
    "\n",
    "# Plot training metrics for all successful configurations\n",
    "for config_id, data in results_database.items():\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        plot_metrics(config_id, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefd1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURATION RESULTS TABLE (sorted by Best Val F1)\n",
      "=======================================================\n",
      "config_id  best_val_acc  best_val_f1\n",
      "  config9        0.5497       0.5421\n",
      " config16        0.5540       0.5418\n",
      "  config5        0.5370       0.5269\n",
      "  config2        0.5109       0.5033\n",
      "  config7        0.5094       0.4987\n",
      "  config4        0.5031       0.4776\n",
      " config18        0.5000       0.4762\n",
      " config11        0.4641       0.4519\n",
      "  config0        0.4815       0.4519\n",
      "  config6        0.4469       0.4235\n",
      "  config3        0.4359       0.4221\n",
      "  config8        0.4453       0.4146\n",
      " config14        0.4492       0.4095\n",
      " config13        0.3869       0.3704\n",
      "  config1        0.3381       0.3297\n",
      " config12        0.0967       0.0487\n",
      " config10        0.0602       0.0117\n",
      " config15        0.0473       0.0117\n",
      " config19        0.0549       0.0032\n",
      " config17        0.0406       0.0024\n"
     ]
    }
   ],
   "source": [
    "# Create a simple table showing config_ids with their best validation accuracy and F1 scores\n",
    "# Extract data from results_database\n",
    "table_data = []\n",
    "for config_id, data in results_database.items():\n",
    "    if config_id == 'config20':\n",
    "        continue\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        table_data.append({\n",
    "            'config_id': config_id,\n",
    "            'best_val_acc': result.get('best_val_acc', 0),\n",
    "            'best_val_f1': result.get('best_val_f1', 0)\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by best_val_f1 (descending)\n",
    "results_table = pd.DataFrame(table_data)\n",
    "results_table = results_table.sort_values('best_val_f1', ascending=False)\n",
    "\n",
    "print(\"CONFIGURATION RESULTS TABLE (sorted by Best Val F1)\")\n",
    "print(\"=\" * 55)\n",
    "print(results_table.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d999aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract successful results for analysis\n",
    "successful_results = {k: v for k, v in results_database.items() if v['status'] == 'success'}\n",
    "\n",
    "if not successful_results:\n",
    "    print(\"No successful configurations to analyze!\")\n",
    "else:\n",
    "    print(f\"Analyzing {len(successful_results)} successful configurations...\")\n",
    "    \n",
    "    # Create results DataFrame with optimization metadata\n",
    "    analysis_data = []\n",
    "    for config_id, data in successful_results.items():\n",
    "        config = data['config']\n",
    "        result = data['result']\n",
    "        opt_meta = data.get('optimization_metadata', {})\n",
    "        \n",
    "        row = {\n",
    "            'config_id': config_id,\n",
    "            'config_name': config['name'],\n",
    "            'best_val_acc': result['best_val_acc'],\n",
    "            'best_val_f1': result['best_val_f1'],\n",
    "            'training_time_min': data['training_time_seconds'] / 60,\n",
    "            'training_type': result.get('training_type', 'single_fold'),\n",
    "            \n",
    "            # Configuration parameters\n",
    "            'use_adam': config['use_adam'],\n",
    "            'estop_thresh': config['estop_thresh'],\n",
    "            'batch_size': config['batch_size'],\n",
    "            'use_class_weights': config['use_class_weights'],\n",
    "            'l2_regularization': config['l2_regularization'],\n",
    "            'has_lr_schedule': config['lr_schedule'] is not None,\n",
    "            'lr_schedule_type': config['lr_schedule']['type'] if config['lr_schedule'] else 'none',\n",
    "            'initial_lr': config['initial_lr'],\n",
    "            'standardize': config['standardize'],\n",
    "            'spec_augment': config['spec_augment'],\n",
    "            'noise_augment': config['noise_augment'],\n",
    "            'num_epochs': config['num_epochs'],\n",
    "            \n",
    "            # NEW OPTIMIZATION METRICS\n",
    "            'mixed_precision_used': opt_meta.get('mixed_precision_used', False),\n",
    "            'gradient_clipping_used': opt_meta.get('gradient_clipping_used', False),\n",
    "            'parallel_folds_used': opt_meta.get('parallel_folds_used', False),\n",
    "            'optimized_dataloaders': opt_meta.get('optimized_dataloaders', False),\n",
    "            'batch_size_optimized': opt_meta.get('batch_size_optimized', False),\n",
    "            'gradient_clipping_value': config.get('gradient_clipping', 0),\n",
    "            'optimization_score': (\n",
    "                opt_meta.get('mixed_precision_used', False) * 2 +\n",
    "                opt_meta.get('gradient_clipping_used', False) * 1 +\n",
    "                opt_meta.get('optimized_dataloaders', False) * 1 +\n",
    "                opt_meta.get('batch_size_optimized', False) * 1\n",
    "            )  # Score out of 5\n",
    "        }\n",
    "        analysis_data.append(row)\n",
    "    \n",
    "    results_df = pd.DataFrame(analysis_data)\n",
    "    \n",
    "    # Sort by F1 score (primary metric) - using best metrics from early stopping\n",
    "    results_df = results_df.sort_values('best_val_f1', ascending=False)\n",
    "    \n",
    "    print(\"TOP 10 CONFIGURATIONS BY BEST F1 SCORE (from early stopping):\")\n",
    "    print(\"=\"*70)\n",
    "    top_10_display = results_df.head(10)[['config_id', 'config_name', 'best_val_f1', 'best_val_acc', \n",
    "                                        'training_time_min', 'mixed_precision_used', 'optimization_score']]\n",
    "    # Round numeric columns to 2 decimal places for better readability\n",
    "    top_10_display_formatted = top_10_display.copy()\n",
    "    top_10_display_formatted['best_val_f1'] = top_10_display_formatted['best_val_f1'].round(4)\n",
    "    top_10_display_formatted['best_val_acc'] = top_10_display_formatted['best_val_acc'].round(4)\n",
    "    top_10_display_formatted['training_time_min'] = top_10_display_formatted['training_time_min'].round(4)\n",
    "    print(top_10_display_formatted.to_string(index=False))\n",
    "    \n",
    "    # Performance optimization analysis\n",
    "    if ENABLE_OPTIMIZATIONS:\n",
    "        print(f\"\\nðŸš€ PERFORMANCE OPTIMIZATION ANALYSIS:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        optimized_configs = results_df[results_df['mixed_precision_used'] == True]\n",
    "        traditional_configs = results_df[results_df['mixed_precision_used'] == False]\n",
    "        \n",
    "        if len(optimized_configs) > 0:\n",
    "            print(f\"Configurations with optimizations: {len(optimized_configs)}\")\n",
    "            print(f\"Average Best F1 (optimized): {optimized_configs['best_val_f1'].mean():.4f}\")\n",
    "            print(f\"Average training time (optimized): {optimized_configs['training_time_min'].mean():.1f} min\")\n",
    "            \n",
    "            if len(traditional_configs) > 0:\n",
    "                print(f\"Average Best F1 (traditional): {traditional_configs['best_val_f1'].mean():.4f}\")\n",
    "                print(f\"Average training time (traditional): {traditional_configs['training_time_min'].mean():.1f} min\")\n",
    "                \n",
    "                # Calculate improvements\n",
    "                f1_improvement = optimized_configs['best_val_f1'].mean() - traditional_configs['best_val_f1'].mean()\n",
    "                time_improvement = traditional_configs['training_time_min'].mean() / optimized_configs['training_time_min'].mean()\n",
    "                \n",
    "                print(f\"\\nðŸ“Š Optimization Impact:\")\n",
    "                print(f\"   â€¢ Best F1 Score improvement: {f1_improvement:+.4f}\")\n",
    "                print(f\"   â€¢ Speed improvement: {time_improvement:.2f}x faster\")\n",
    "        \n",
    "        # Optimization feature correlation\n",
    "        print(f\"\\nðŸ”§ Optimization Feature Analysis:\")\n",
    "        opt_features = ['mixed_precision_used', 'gradient_clipping_used', 'batch_size_optimized']\n",
    "        for feature in opt_features:\n",
    "            if feature in results_df.columns:\n",
    "                feature_on = results_df[results_df[feature] == True]['best_val_f1'].mean()\n",
    "                feature_off = results_df[results_df[feature] == False]['best_val_f1'].mean()\n",
    "                improvement = feature_on - feature_off\n",
    "                print(f\"   â€¢ {feature}: {improvement:+.4f} Best F1 improvement\")\n",
    "    \n",
    "    # Best configuration details\n",
    "    best_config_id = results_df.iloc[0]['config_id']\n",
    "    best_config_data = successful_results[best_config_id]\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST CONFIGURATION: {best_config_id}\")\n",
    "    print(f\"Name: {best_config_data['config']['name']}\")\n",
    "    print(f\"Best Val F1: {results_df.iloc[0]['best_val_f1']:.4f}\")\n",
    "    print(f\"Best Val Accuracy: {results_df.iloc[0]['best_val_acc']:.4f}\")\n",
    "    print(f\"Training Time: {results_df.iloc[0]['training_time_min']:.1f} minutes\")\n",
    "    print(f\"Optimizations Used: {results_df.iloc[0]['optimization_score']}/5\")\n",
    "    \n",
    "    if results_df.iloc[0]['mixed_precision_used']:\n",
    "        print(\"âœ… Used Mixed Precision Training\")\n",
    "    if results_df.iloc[0]['gradient_clipping_used']:\n",
    "        print(f\"âœ… Used Gradient Clipping ({results_df.iloc[0]['gradient_clipping_value']})\")\n",
    "    if results_df.iloc[0]['optimized_dataloaders']:\n",
    "        print(\"âœ… Used Optimized DataLoaders\")\n",
    "    if results_df.iloc[0]['batch_size_optimized']:\n",
    "        print(\"âœ… Used Optimized Batch Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "if len(successful_results) > 0:\n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('Configuration Results Analysis (Best Metrics from Early Stopping)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. F1 Score comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    results_df_plot = results_df.head(15)  # Top 15 for readability\n",
    "    bars1 = ax1.bar(range(len(results_df_plot)), results_df_plot['best_val_f1'], alpha=0.7, color='skyblue')\n",
    "    ax1.set_title('Best Validation F1 Score by Configuration')\n",
    "    ax1.set_xlabel('Configuration Rank')\n",
    "    ax1.set_ylabel('Best F1 Score')\n",
    "    ax1.set_xticks(range(len(results_df_plot)))\n",
    "    ax1.set_xticklabels(results_df_plot['config_id'], rotation=45)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars1):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 2. Accuracy vs F1 scatter\n",
    "    ax2 = axes[0, 1]\n",
    "    scatter = ax2.scatter(results_df['best_val_acc'], results_df['best_val_f1'], \n",
    "                        c=results_df['training_time_min'], cmap='viridis', alpha=0.7, s=100)\n",
    "    ax2.set_xlabel('Best Validation Accuracy')\n",
    "    ax2.set_ylabel('Best Validation F1 Score')\n",
    "    ax2.set_title('Best Accuracy vs Best F1 Score (colored by training time)')\n",
    "    plt.colorbar(scatter, ax=ax2, label='Training Time (min)')\n",
    "    \n",
    "    # Add best point annotation\n",
    "    best_acc = results_df.iloc[0]['best_val_acc']\n",
    "    best_f1 = results_df.iloc[0]['best_val_f1']\n",
    "    ax2.annotate(f'Best: {best_config_id}', xy=(best_acc, best_f1), \n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    # 3. Parameter impact - Batch size\n",
    "    ax3 = axes[0, 2]\n",
    "    batch_impact = results_df.groupby('batch_size')['best_val_f1'].agg(['mean', 'count']).reset_index()\n",
    "    bars3 = ax3.bar(batch_impact['batch_size'], batch_impact['mean'], alpha=0.7, color='lightcoral')\n",
    "    ax3.set_title('Average Best F1 Score by Batch Size')\n",
    "    ax3.set_xlabel('Batch Size')\n",
    "    ax3.set_ylabel('Average Best F1 Score')\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, row in batch_impact.iterrows():\n",
    "        ax3.text(row['batch_size'], row['mean'] + 0.002, f'n={row[\"count\"]}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 4. Learning rate impact\n",
    "    ax4 = axes[1, 0]\n",
    "    lr_bins = pd.cut(results_df['initial_lr'], bins=5)\n",
    "    lr_impact = results_df.groupby(lr_bins)['best_val_f1'].agg(['mean', 'count']).reset_index()\n",
    "    lr_labels = [f'{interval.left:.4f}-{interval.right:.4f}' for interval in lr_impact['initial_lr']]\n",
    "    bars4 = ax4.bar(range(len(lr_labels)), lr_impact['mean'], alpha=0.7, color='lightgreen')\n",
    "    ax4.set_title('Average Best F1 Score by Learning Rate Range')\n",
    "    ax4.set_xlabel('Learning Rate Range')\n",
    "    ax4.set_ylabel('Average Best F1 Score')\n",
    "    ax4.set_xticks(range(len(lr_labels)))\n",
    "    ax4.set_xticklabels(lr_labels, rotation=45)\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 5. Augmentation impact\n",
    "    ax5 = axes[1, 1]\n",
    "    augment_combinations = results_df.groupby(['spec_augment', 'noise_augment'])['best_val_f1'].agg(['mean', 'count']).reset_index()\n",
    "    augment_labels = []\n",
    "    for _, row in augment_combinations.iterrows():\n",
    "        spec = 'Spec' if row['spec_augment'] else 'NoSpec'\n",
    "        noise = 'Noise' if row['noise_augment'] else 'NoNoise'\n",
    "        augment_labels.append(f'{spec}+{noise}')\n",
    "    \n",
    "    bars5 = ax5.bar(range(len(augment_labels)), augment_combinations['mean'], alpha=0.7, color='orange')\n",
    "    ax5.set_title('Average Best F1 Score by Augmentation Strategy')\n",
    "    ax5.set_xlabel('Augmentation Combination')\n",
    "    ax5.set_ylabel('Average Best F1 Score')\n",
    "    ax5.set_xticks(range(len(augment_labels)))\n",
    "    ax5.set_xticklabels(augment_labels, rotation=45)\n",
    "    ax5.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, row in augment_combinations.iterrows():\n",
    "        ax5.text(i, row['mean'] + 0.002, f'n={row[\"count\"]}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 6. Training time vs performance\n",
    "    ax6 = axes[1, 2]\n",
    "    ax6.scatter(results_df['training_time_min'], results_df['best_val_f1'], alpha=0.7, s=100, color='purple')\n",
    "    ax6.set_xlabel('Training Time (minutes)')\n",
    "    ax6.set_ylabel('Best Validation F1 Score')\n",
    "    ax6.set_title('Training Time vs Best Performance')\n",
    "    ax6.grid(alpha=0.3)\n",
    "    \n",
    "    # Add trendline\n",
    "    z = np.polyfit(results_df['training_time_min'], results_df['best_val_f1'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax6.plot(results_df['training_time_min'], p(results_df['training_time_min']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv('../database/meta/configuration_results.csv', index=False)\n",
    "    print(f\"\\nðŸ’¾ Results saved to ../database/meta/configuration_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter correlation analysis\n",
    "if len(successful_results) > 0:\n",
    "    print(\"\\nPARAMETER CORRELATION ANALYSIS (using best metrics from early stopping):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create correlation matrix for numerical parameters\n",
    "    numeric_params = ['estop_thresh', 'batch_size', 'l2_regularization', 'initial_lr', \n",
    "                     'num_epochs', 'best_val_f1', 'best_val_acc', 'training_time_min']\n",
    "    \n",
    "    correlation_data = results_df[numeric_params].corr()\n",
    "    \n",
    "    # Focus on correlations with performance metrics\n",
    "    f1_correlations = correlation_data['best_val_f1'].abs().sort_values(ascending=False)\n",
    "    acc_correlations = correlation_data['best_val_acc'].abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Parameters most correlated with Best F1 Score:\")\n",
    "    for param, corr in f1_correlations.items():\n",
    "        if param != 'best_val_f1':\n",
    "            print(f\"  {param}: {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\nParameters most correlated with Best Accuracy:\")\n",
    "    for param, corr in acc_correlations.items():\n",
    "        if param != 'best_val_acc':\n",
    "            print(f\"  {param}: {corr:.3f}\")\n",
    "    \n",
    "    # Categorical parameter analysis\n",
    "    print(f\"\\nCATEGORICAL PARAMETER ANALYSIS:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    categorical_params = ['use_adam', 'use_class_weights', 'has_lr_schedule', \n",
    "                        'standardize', 'spec_augment', 'noise_augment']\n",
    "    \n",
    "    for param in categorical_params:\n",
    "        if param in results_df.columns:\n",
    "            grouped = results_df.groupby(param)['best_val_f1'].agg(['mean', 'std', 'count'])\n",
    "            print(f\"\\n{param}:\")\n",
    "            print(grouped)\n",
    "    \n",
    "    # Best parameter combinations\n",
    "    print(f\"\\nPARAMETER COMBINATIONS FROM BEST PERFORMERS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Top 3 configurations analysis\n",
    "    top_3 = results_df.head(3)\n",
    "    for i, (_, row) in enumerate(top_3.iterrows(), 1):\n",
    "        print(f\"\\n#{i} - {row['config_id']} ({row['config_name']}):\")\n",
    "        print(f\"  Best F1: {row['best_val_f1']:.4f}, Best Acc: {row['best_val_acc']:.4f}\")\n",
    "        print(f\"  Batch Size: {row['batch_size']}, LR: {row['initial_lr']:.4f}\")\n",
    "        print(f\"  L2: {row['l2_regularization']:.2e}, Early Stop: {row['estop_thresh']}\")\n",
    "        print(f\"  Augmentation: Spec={row['spec_augment']}, Noise={row['noise_augment']}\")\n",
    "        print(f\"  Optimizer: {'Adam' if row['use_adam'] else 'SGD'}, Class Weights: {row['use_class_weights']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71389ab",
   "metadata": {},
   "source": [
    "## Configuration Recommendations\n",
    "\n",
    "Based on the results, provide recommendations for future configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(successful_results) > 0:\n",
    "    print(\"ðŸŽ¯ OPTIMIZED CONFIGURATION RECOMMENDATIONS (based on best early stopping results)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Analyze best performing configurations\n",
    "    top_5 = results_df.head(5)\n",
    "    \n",
    "    # Extract common patterns from top performers\n",
    "    common_patterns = {}\n",
    "    \n",
    "    # Optimizer preference\n",
    "    adam_count = top_5['use_adam'].sum()\n",
    "    common_patterns['optimizer'] = 'Adam' if adam_count >= 3 else 'Mixed'\n",
    "    \n",
    "    # Batch size trends (consider optimization adjustments)\n",
    "    avg_batch_size = top_5['batch_size'].mean()\n",
    "    common_patterns['batch_size_range'] = f\"{top_5['batch_size'].min()}-{top_5['batch_size'].max()}\"\n",
    "    \n",
    "    # Learning rate trends\n",
    "    avg_lr = top_5['initial_lr'].mean()\n",
    "    common_patterns['lr_range'] = f\"{top_5['initial_lr'].min():.4f}-{top_5['initial_lr'].max():.4f}\"\n",
    "    \n",
    "    # Regularization trends\n",
    "    avg_l2 = top_5['l2_regularization'].mean()\n",
    "    common_patterns['l2_range'] = f\"{top_5['l2_regularization'].min():.2e}-{top_5['l2_regularization'].max():.2e}\"\n",
    "    \n",
    "    # Augmentation preferences\n",
    "    spec_aug_count = top_5['spec_augment'].sum()\n",
    "    noise_aug_count = top_5['noise_augment'].sum()\n",
    "    \n",
    "    # NEW: Optimization preferences\n",
    "    mixed_precision_count = top_5['mixed_precision_used'].sum()\n",
    "    gradient_clip_count = top_5['gradient_clipping_used'].sum()\n",
    "    optimized_batch_count = top_5['batch_size_optimized'].sum()\n",
    "    \n",
    "    print(\"PATTERNS FROM TOP 5 BEST CONFIGURATIONS:\")\n",
    "    print(\"-\"*45)\n",
    "    print(f\"â€¢ Preferred Optimizer: {common_patterns['optimizer']}\")\n",
    "    print(f\"â€¢ Effective Batch Size Range: {common_patterns['batch_size_range']}\")\n",
    "    print(f\"â€¢ Optimal Learning Rate Range: {common_patterns['lr_range']}\")\n",
    "    print(f\"â€¢ L2 Regularization Range: {common_patterns['l2_range']}\")\n",
    "    print(f\"â€¢ SpecAugment Usage: {spec_aug_count}/5 top configs\")\n",
    "    print(f\"â€¢ Noise Augmentation Usage: {noise_aug_count}/5 top configs\")\n",
    "    \n",
    "    # NEW: Optimization patterns\n",
    "    print(f\"\\nðŸš€ OPTIMIZATION PATTERNS IN TOP PERFORMERS:\")\n",
    "    print(\"-\"*45)\n",
    "    print(f\"â€¢ Mixed Precision Usage: {mixed_precision_count}/5 top configs\")\n",
    "    print(f\"â€¢ Gradient Clipping Usage: {gradient_clip_count}/5 top configs\")\n",
    "    print(f\"â€¢ Optimized Batch Sizes: {optimized_batch_count}/5 top configs\")\n",
    "    \n",
    "    if mixed_precision_count >= 4:\n",
    "        print(\"âœ… Strong recommendation: Enable Mixed Precision Training\")\n",
    "    if gradient_clip_count >= 3:\n",
    "        print(\"âœ… Recommendation: Use Gradient Clipping for stability\")\n",
    "    \n",
    "    # Specific recommendations\n",
    "    print(f\"\\nRECOMMENDED OPTIMIZED CONFIGURATION:\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    best_config = successful_results[results_df.iloc[0]['config_id']]['config']\n",
    "    \n",
    "    # Base configuration from results\n",
    "    recommended_config = {\n",
    "        'name': 'Optimized Based on Best Early Stopping Results',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': int(top_5['estop_thresh'].median()),\n",
    "        'batch_size': int(top_5['batch_size'].median()),\n",
    "        'use_class_weights': top_5['use_class_weights'].mode()[0],\n",
    "        'l2_regularization': top_5['l2_regularization'].median(),\n",
    "        'lr_schedule': best_config['lr_schedule'],\n",
    "        'initial_lr': top_5['initial_lr'].median(),\n",
    "        'standardize': True,  # Almost always beneficial\n",
    "        'spec_augment': spec_aug_count >= 3,\n",
    "        'noise_augment': noise_aug_count >= 3,\n",
    "        'num_epochs': int(top_5['num_epochs'].median()),\n",
    "        \n",
    "        # NEW: Optimization recommendations based on results\n",
    "        'mixed_precision': mixed_precision_count >= 3,\n",
    "        'gradient_clipping': top_5['gradient_clipping_value'].median() if gradient_clip_count >= 3 else 0,\n",
    "        'parallel_folds': False,  # For single fold; set True for cross-validation\n",
    "        'max_parallel_folds': 2,  # Conservative for RTX 5080\n",
    "        'optimize_dataloaders': True,  # Always beneficial\n",
    "    }\n",
    "    \n",
    "    print(\"```python\")\n",
    "    print(\"# OPTIMIZED CONFIGURATION FOR RTX 5080 + Ryzen 9 7950X\")\n",
    "    print(\"optimized_config = {\")\n",
    "    for key, value in recommended_config.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"    '{key}': '{value}',\")\n",
    "        else:\n",
    "            print(f\"    '{key}': {value},\")\n",
    "    print(\"}\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    # Performance expectations with optimizations\n",
    "    expected_f1 = top_5['best_val_f1'].mean()\n",
    "    f1_std = top_5['best_val_f1'].std()\n",
    "    expected_time = top_5['training_time_min'].mean()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š EXPECTED PERFORMANCE:\")\n",
    "    print(f\"â€¢ Expected Best F1 Score: {expected_f1:.4f} Â± {f1_std:.4f}\")\n",
    "    print(f\"â€¢ Expected Training Time: ~{expected_time:.1f} minutes\")\n",
    "    \n",
    "    if ENABLE_OPTIMIZATIONS and optimization_benchmarks['speedup_ratios']:\n",
    "        avg_speedup = np.mean(optimization_benchmarks['speedup_ratios'])\n",
    "        traditional_time = expected_time * avg_speedup\n",
    "        print(f\"â€¢ Traditional Training Time: ~{traditional_time:.1f} minutes\")\n",
    "        print(f\"â€¢ Speed Improvement: {avg_speedup:.2f}x faster\")\n",
    "        print(f\"â€¢ Time Saved per Config: ~{traditional_time - expected_time:.1f} minutes\")\n",
    "    \n",
    "    # Hardware-specific recommendations\n",
    "    print(f\"\\nðŸ–¥ï¸ HARDWARE-SPECIFIC RECOMMENDATIONS:\")\n",
    "    print(\"-\"*45)\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name()\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        \n",
    "        if \"RTX\" in gpu_name and gpu_memory >= 14:\n",
    "            print(f\"âœ… RTX 5080 Detected ({gpu_memory:.0f}GB VRAM):\")\n",
    "            print(f\"   â€¢ Use batch_size up to 80 with mixed precision\")\n",
    "            print(f\"   â€¢ Enable parallel_folds=True for cross-validation\")\n",
    "            print(f\"   â€¢ Set max_parallel_folds=2-3 for optimal memory usage\")\n",
    "            print(f\"   â€¢ Mixed precision provides ~50% speedup on this GPU\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "            print(f\"   â€¢ Use conservative batch sizes\")\n",
    "            print(f\"   â€¢ Mixed precision may provide less benefit\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No successful configurations to analyze!\")\n",
    "    print(\"Check the failed configurations and adjust parameters.\")\n",
    "    print(\"\\nðŸ”§ Troubleshooting Optimization Issues:\")\n",
    "    print(\"â€¢ Reduce batch_size if getting OOM errors\")\n",
    "    print(\"â€¢ Set mixed_precision=False if encountering numerical instability\")\n",
    "    print(\"â€¢ Lower gradient_clipping value if training becomes unstable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69614ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrices for All Configurations\n",
    "from utils.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"ðŸ” Plotting confusion matrices for all successful configurations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get successful configurations (those with confusion matrices)\n",
    "configs_with_cm = {k: v for k, v in results_database.items() \n",
    "                    if v['status'] == 'success' and v.get('result') and 'confusion_matrix' in v['result']}\n",
    "\n",
    "if not configs_with_cm:\n",
    "    print(\"âŒ No configurations with confusion matrices found!\")\n",
    "    print(\"Available keys in successful results:\")\n",
    "    for k, v in results_database.items():\n",
    "        if v['status'] == 'success' and v.get('result'):\n",
    "            print(f\"  {k}: {list(v['result'].keys())}\")\n",
    "else:\n",
    "    print(f\"ðŸ“Š Found {len(configs_with_cm)} configurations with confusion matrices\")\n",
    "    \n",
    "    # Sort configurations by F1 score (descending)\n",
    "    sorted_configs = sorted(configs_with_cm.items(), \n",
    "                            key=lambda x: x[1]['result']['final_val_f1'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Plot individual confusion matrices for top 5 configurations\n",
    "    top_configs = sorted_configs[:5]  # Limit to top 5 for readability\n",
    "    \n",
    "    for i, (config_id, config_data) in enumerate(top_configs):\n",
    "        result = config_data['result']\n",
    "        cm = result['confusion_matrix']\n",
    "        f1_score = result['final_val_f1']\n",
    "        val_acc = result['final_val_acc']\n",
    "        config_name = config_data['config']['name']\n",
    "        \n",
    "        # Use the plot_confusion_matrix function from metrics\n",
    "        title = f\"{config_id}: {config_name}\\nF1: {f1_score:.4f} | Acc: {val_acc:.4f}\"\n",
    "        plot_confusion_matrix(cm, title=title, figsize=(10, 8))\n",
    "    \n",
    "    # Create a summary comparison plot\n",
    "    if len(sorted_configs) > 1:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Plot top 6 configurations in a grid\n",
    "        plot_count = min(6, len(sorted_configs))\n",
    "        \n",
    "        for idx, (config_id, config_data) in enumerate(sorted_configs[:plot_count]):\n",
    "            result = config_data['result']\n",
    "            cm = result['confusion_matrix']\n",
    "            f1_score = result['final_val_f1']\n",
    "            val_acc = result['final_val_acc']\n",
    "            \n",
    "            # Normalize confusion matrix to percentages\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "            \n",
    "            # Create heatmap on subplot\n",
    "            ax = axes[idx]\n",
    "            sns.heatmap(cm_normalized, \n",
    "                        annot=True, \n",
    "                        fmt='.1f',\n",
    "                        cmap='Blues',\n",
    "                        square=True,\n",
    "                        ax=ax,\n",
    "                        cbar_kws={'label': 'Percentage (%)'})\n",
    "            \n",
    "            ax.set_title(f'{config_id}\\nF1: {f1_score:.4f} | Acc: {val_acc:.4f}', \n",
    "                        fontsize=12, pad=10)\n",
    "            ax.set_ylabel('True Label')\n",
    "            ax.set_xlabel('Predicted Label')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(plot_count, len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Top Configuration Confusion Matrices Comparison', fontsize=16, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nðŸ“ˆ Confusion Matrix Summary:\")\n",
    "    print(f\"Total configurations with confusion matrices: {len(configs_with_cm)}\")\n",
    "    \n",
    "    best_config_id, best_config_data = sorted_configs[0]\n",
    "    best_result = best_config_data['result']\n",
    "    print(f\"Best performing configuration: {best_config_id}\")\n",
    "    print(f\"  - F1 Score: {best_result['final_val_f1']:.4f}\")\n",
    "    print(f\"  - Accuracy: {best_result['final_val_acc']:.4f}\")\n",
    "    print(f\"  - Loss: {best_result['final_val_loss']:.4f}\")\n",
    "    \n",
    "    if len(sorted_configs) > 1:\n",
    "        worst_config_id, worst_config_data = sorted_configs[-1]\n",
    "        worst_result = worst_config_data['result']\n",
    "        improvement = best_result['final_val_f1'] - worst_result['final_val_f1']\n",
    "        print(f\"Worst performing configuration: {worst_config_id}\")\n",
    "        print(f\"  - F1 Score: {worst_result['final_val_f1']:.4f}\")\n",
    "        print(f\"F1 Score improvement from worst to best: {improvement:.4f} ({improvement/worst_result['final_val_f1']*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Confusion matrix plotting completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete results for future reference\n",
    "if len(successful_results) > 0:\n",
    "    # Create a clean version of results_database without problematic objects\n",
    "    clean_results_database = {}\n",
    "    for config_id, data in results_database.items():\n",
    "        clean_data = {\n",
    "            'config': data['config'],\n",
    "            'status': data['status'],\n",
    "            'optimization_metadata': data.get('optimization_metadata', {}),\n",
    "            'timestamp': data.get('timestamp', ''),\n",
    "            'training_time_seconds': data.get('training_time_seconds', 0)\n",
    "        }\n",
    "        \n",
    "        if data['status'] == 'success' and data.get('result'):\n",
    "            # Extract only serializable parts of the result - using best metrics\n",
    "            result = data['result']\n",
    "            clean_data['result'] = {\n",
    "                'best_val_acc': result.get('best_val_acc', 0),\n",
    "                'best_val_f1': result.get('best_val_f1', 0),\n",
    "                'best_val_loss': result.get('best_val_loss', 0),\n",
    "                'training_time': result.get('training_time', 0),\n",
    "                'training_type': result.get('training_type', 'single_fold'),\n",
    "                'parallel_execution': result.get('parallel_execution', False),\n",
    "                # Include history without problematic objects\n",
    "                'history': {\n",
    "                    'early_stopped': result.get('history', {}).get('early_stopped', False),\n",
    "                    'best_epoch': result.get('history', {}).get('best_epoch', 0),\n",
    "                    'total_epochs': result.get('history', {}).get('total_epochs', 0)\n",
    "                }\n",
    "            }\n",
    "        elif data['status'] == 'failed':\n",
    "            clean_data['error'] = data.get('error', 'Unknown error')\n",
    "        \n",
    "        clean_results_database[config_id] = clean_data\n",
    "    \n",
    "    # Create a comprehensive results file\n",
    "    complete_results = {\n",
    "        'metadata': {\n",
    "            'test_date': training_start_time.isoformat(),\n",
    "            'total_configs_tested': len(configurations),\n",
    "            'successful_configs': len(successful_results),\n",
    "            'failed_configs': len(failed_configs),\n",
    "            'total_duration_hours': total_duration / 3600,\n",
    "            'dataset_info': {\n",
    "                'total_samples': len(features),\n",
    "                'num_classes': len(np.unique(labels)),\n",
    "                'num_authors': len(np.unique(authors)),\n",
    "                'feature_shape': list(features.shape)\n",
    "            },\n",
    "            'note': 'All metrics are from best model state (early stopping), not final training epoch'\n",
    "        },\n",
    "        'configurations': configurations,\n",
    "        'results': clean_results_database,\n",
    "        'analysis': {\n",
    "            'top_10_configs': results_df.head(10).to_dict('records'),\n",
    "            'parameter_correlations': correlation_data.to_dict() if 'correlation_data' in locals() else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Convert numpy types to native Python types for JSON serialization\n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        return obj\n",
    "    \n",
    "    # Save as JSON for future analysis\n",
    "    try:\n",
    "        # Save to CSV\n",
    "        results_df.to_csv('../models/reports/configuration_results.csv', index=False)\n",
    "\n",
    "        with open('../models/reports/complete_configuration_results.json', 'w') as f:\n",
    "            # Clean the data for JSON serialization\n",
    "            clean_results = json.loads(json.dumps(complete_results, default=convert_numpy))\n",
    "            json.dump(clean_results, f, indent=2)\n",
    "        \n",
    "        print(\"ðŸ’¾ Complete results saved to:\")\n",
    "        print(\"  - ../models/reports/configuration_results.csv (tabular data)\")\n",
    "        print(\"  - ../models/reports/complete_configuration_results.json (full results)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Warning: Could not save JSON file due to serialization issue: {e}\")\n",
    "        print(\"ðŸ’¾ Results saved to CSV only:\")\n",
    "        print(\"  - ../models/reports/configuration_results.csv (tabular data)\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Configuration testing completed successfully!\")\n",
    "    print(f\"Best configuration: {results_df.iloc[0]['config_id']} with BEST F1 score of {results_df.iloc[0]['best_val_f1']:.4f}\")\n",
    "    print(f\"âœ… All metrics are from the best model state (early stopping), not arbitrary final epoch\")\n",
    "else:\n",
    "    print(\"âŒ No results to save - all configurations failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
