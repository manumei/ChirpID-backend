{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7495a4",
   "metadata": {},
   "source": [
    "In this one, test the different architectures with the top candidate configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f76cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  CUDA not available - running on CPU (will be slow)\")\n",
    "\n",
    "# Performance optimization settings\n",
    "ENABLE_OPTIMIZATIONS = True  # Set to False to disable all optimizations\n",
    "ENABLE_PARALLEL_FOLDS = False  # Set to True for cross-validation mode\n",
    "MAX_PARALLEL_FOLDS = -1  # Adjust based on GPU memory\n",
    "\n",
    "def load_npy_data(specs_dir: str, specs_csv_path: str) -> Tuple[np.ndarray, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Load spectrograms from .npy files and metadata from CSV.\n",
    "    \n",
    "    Args:\n",
    "        specs_dir (str): Directory containing .npy spectrogram files\n",
    "        specs_csv_path (str): Path to CSV file containing metadata (filename, class_id, author)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.array, np.array]: Returns features, labels, and authors.\n",
    "        Features are already normalized to [0,1] and shaped as (N, 1, 224, 313)\n",
    "    \"\"\"\n",
    "    # Load metadata CSV\n",
    "    df = pd.read_csv(specs_csv_path)\n",
    "    \n",
    "    print(f\"Metadata shape: {df.shape}\")\n",
    "    print(f\"Number of classes: {df['class_id'].nunique()}\")\n",
    "    print(f\"Number of authors: {df['author'].nunique()}\")\n",
    "    \n",
    "    # Extract labels and authors\n",
    "    labels = df['class_id'].values.astype(np.int64)\n",
    "    authors = df['author'].values\n",
    "    filenames = df['filename'].values\n",
    "    \n",
    "    # Load spectrograms from .npy files\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        spec_path = os.path.join(specs_dir, filename)\n",
    "        \n",
    "        if os.path.exists(spec_path):\n",
    "            try:\n",
    "                # Load .npy file - already normalized to [0,1] as float32\n",
    "                spec_array = np.load(spec_path)\n",
    "                \n",
    "                # Add channel dimension: (1, height, width)\n",
    "                spec_array = spec_array[np.newaxis, ...]\n",
    "                \n",
    "                features_list.append(spec_array)\n",
    "                valid_indices.append(i)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {spec_path}\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features = np.array(features_list, dtype=np.float32)\n",
    "    \n",
    "    # Filter labels and authors to match loaded features\n",
    "    labels = labels[valid_indices]\n",
    "    authors = authors[valid_indices]\n",
    "    \n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Authors shape: {authors.shape}\")\n",
    "    print(f\"Unique classes: {len(np.unique(labels))}\")\n",
    "    print(f\"Unique authors: {len(np.unique(authors))}\")\n",
    "    print(f\"Successfully loaded {len(features)} out of {len(filenames)} spectrograms\")\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return features, labels, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ba291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New pipeline using .npy spectrograms from specs/ directory\n",
    "specs_dir = os.path.join('..', 'database', 'specs')\n",
    "specs_csv_path = os.path.join('..', 'database', 'meta', 'final_specs.csv')\n",
    "features, labels, authors = load_npy_data(specs_dir, specs_csv_path)\n",
    "\n",
    "# Display class distribution\n",
    "plt.figure(figsize=(9, 5))\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique_labels, counts, alpha=0.7)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xticks(unique_labels)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average samples per class: {len(labels) / len(unique_labels):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a99d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with a set seed\n",
    "from utils.split import get_set_seed_indices, get_set_seed_kfold_indices, display_split_statistics\n",
    "seed_single = 245323 # Quality: 0.2671\n",
    "seed_kfold = 11052 # Quality: 0.3332\n",
    "\n",
    "single_fold_split = get_set_seed_indices(\n",
    "    features=features,\n",
    "    labels=labels, \n",
    "    authors=authors,\n",
    "    test_size=0.2,\n",
    "    seed=seed_single)\n",
    "\n",
    "kfold_splits = get_set_seed_kfold_indices(\n",
    "    features=features,\n",
    "    labels=labels,\n",
    "    authors=authors,\n",
    "    n_splits=4,\n",
    "    seed=seed_kfold)\n",
    "\n",
    "display_split_statistics(single_fold_split, \"single\")\n",
    "display_split_statistics(kfold_splits, \"kfold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Configurations\n",
    "configurations = {\n",
    "    'configA' : {\n",
    "        'name': 'Parameters Frankenstein',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 36,\n",
    "        'batch_size': 40,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 0.0003,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.97},\n",
    "        'initial_lr': 0.0024, # also try 0.00137\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': True,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': False,\n",
    "        'max_parallel_folds': 2,\n",
    "        'optimize_dataloaders': True,\n",
    "    },\n",
    "\n",
    "    'configB': {\n",
    "        'name': 'Balanced Classes Focus',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 28,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3e-4,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.0012,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    \n",
    "    'configC': {\n",
    "        'name': 'Chaos Theory',\n",
    "        'use_adam': True,\n",
    "        'estop_thresh': 37,\n",
    "        'batch_size': 45,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 3.7e-4,\n",
    "        'lr_schedule': {'type': 'cosine', 'T_max': 73},\n",
    "        'initial_lr': 0.00137,\n",
    "        'standardize': False,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 247,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 0.73,\n",
    "        'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    \n",
    "    'configD': {  # AdamW variant of config9\n",
    "        'name': 'Balanced Classes AdamW',\n",
    "        'use_adam': 'adamw',\n",
    "        'estop_thresh': 35,\n",
    "        'batch_size': 32,\n",
    "        'use_class_weights': True,\n",
    "        'l2_regularization': 0.02,\n",
    "        'lr_schedule': {'type': 'exponential', 'gamma': 0.96},\n",
    "        'initial_lr': 0.003,\n",
    "        'standardize': True,\n",
    "        'spec_augment': True,\n",
    "        'noise_augment': False,\n",
    "        'num_epochs': 220,\n",
    "        'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "        'gradient_clipping': 1.0,\n",
    "        'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "        'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results plotting\n",
    "# Inspired on this code, copied from ModelConfiguring.ipynb\n",
    "\n",
    "# importlib.reload(utils.metrics)\n",
    "# from utils.metrics import plot_metrics\n",
    "\n",
    "# # Plot training metrics for all successful configurations\n",
    "# for config_id, data in results_database.items():\n",
    "#     if data['status'] == 'success' and 'result' in data:\n",
    "#         result = data['result']\n",
    "#         plot_metrics(config_id, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restuls table display\n",
    "# Inspired on this code, copied from ModelConfiguring.ipynb\n",
    "\n",
    "# table_data = []\n",
    "# for config_id, data in results_database.items():\n",
    "#     if data['status'] == 'success' and 'result' in data:\n",
    "#         result = data['result']\n",
    "#         table_data.append({\n",
    "#             'config_id': config_id,\n",
    "#             'best_val_acc': result.get('best_val_acc', 0),\n",
    "#             'best_val_f1': result.get('best_val_f1', 0)\n",
    "#         })\n",
    "\n",
    "# # Create DataFrame and sort by best_val_f1 (descending)\n",
    "# results_table = pd.DataFrame(table_data)\n",
    "# results_table = results_table.sort_values('best_val_f1', ascending=False)\n",
    "\n",
    "# print(\"CONFIGURATION RESULTS TABLE (sorted by Best Val F1)\")\n",
    "# print(\"=\" * 55)\n",
    "# print(results_table.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5x4 plot of the column graphs for each architecture (20 models, 20 plots, each with 5 columns (4 config F1s & highest F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis and Recommendations (based mostly on F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save json and csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
