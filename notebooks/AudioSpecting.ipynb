{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e44d4e",
   "metadata": {},
   "source": [
    "Este agarra los audio segments de audio_segments/, los procesa, y carga los spectrograms finales a specs/ como archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.data_processing import reduce_noise_seg, create_single_spectrogram_npy, save_test_audio, plot_summary, load_audio_segments_from_disk, clean_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d662586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrograms_from_segments_npy(segments, spectrogram_dir, output_csv_path, \n",
    "                                        test_audios_dir=None, mels=224, hoplen=512, \n",
    "                                        nfft=2048, noise_reduce=False):\n",
    "    \"\"\"\n",
    "    Create spectrograms from extracted audio segments and save as .npy files.\n",
    "    \n",
    "    Args:\n",
    "        segments (list): List of segment dictionaries from extract_audio_segments\n",
    "        spectrogram_dir (str): Directory to save spectrogram .npy files\n",
    "        output_csv_path (str): Path to save the output CSV\n",
    "        test_audios_dir (str, optional): Directory to save test audio samples\n",
    "        mels (int): Number of mel bands for spectrogram\n",
    "        hoplen (int): Hop length for spectrogram\n",
    "        nfft (int): FFT window size\n",
    "        noise_reduce (bool): Whether to apply noise reduction\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with spectrogram metadata\n",
    "    \"\"\"\n",
    "    print(f\"Creating spectrograms from {len(segments)} segments...\")\n",
    "    \n",
    "    os.makedirs(spectrogram_dir, exist_ok=True)\n",
    "    if test_audios_dir:\n",
    "        os.makedirs(test_audios_dir, exist_ok=True)\n",
    "    \n",
    "    spectrogram_records = []\n",
    "    saved_test_audios = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for i, segment_info in enumerate(segments):\n",
    "        # Apply noise reduction if requested\n",
    "        if noise_reduce:\n",
    "            segment_info['audio_data'] = reduce_noise_seg(\n",
    "                segment_info['audio_data'], \n",
    "                srate=segment_info['sr'], \n",
    "                filename=segment_info['original_filename'], \n",
    "                class_id=segment_info['class_id']\n",
    "            )\n",
    "        \n",
    "        # Create spectrogram as .npy file\n",
    "        record = create_single_spectrogram_npy(segment_info, spectrogram_dir, mels, hoplen, nfft)\n",
    "        \n",
    "        if record is not None:\n",
    "            # Save test audio if requested (first 10 only)\n",
    "            if test_audios_dir and saved_test_audios < 10:\n",
    "                save_test_audio(segment_info, test_audios_dir)\n",
    "                saved_test_audios += 1\n",
    "            \n",
    "            spectrogram_records.append(record)\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "    \n",
    "    # Create and save final DataFrame\n",
    "    final_df = pd.DataFrame(spectrogram_records)\n",
    "    final_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Spectrogram generation summary:\")\n",
    "    print(f\"  Total processed: {len(segments)}\")\n",
    "    print(f\"  Successfully created: {len(spectrogram_records)}\")\n",
    "    print(f\"  Skipped due to errors: {skipped_count}\")\n",
    "    \n",
    "    plot_summary(final_df, output_csv_path)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ad697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "# Input: Audio segments from AudioExtracting notebook\n",
    "segments_dir = os.path.join('..', 'database', 'audio_segments')\n",
    "segments_csv_path = os.path.join('..', 'database', 'meta', 'audio_segments.csv')\n",
    "\n",
    "# Output: Spectrograms and metadata - using specs/ directory for .npy files\n",
    "specs_dir = os.path.join('..', 'database', 'specs')\n",
    "output_csv = os.path.join('..', 'database', 'meta', 'final_specs.csv')\n",
    "test_audios_dir = os.path.join('..', 'database', 'test_audios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the segments CSV and plot distribution of samples per class\n",
    "segments_df = pd.read_csv(segments_csv_path)\n",
    "\n",
    "# Count samples per class\n",
    "class_counts = segments_df['class_id'].value_counts().sort_index()\n",
    "\n",
    "# Create the plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Distribution of Audio Segments per Class')\n",
    "plt.xticks(class_counts.index)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    plt.text(class_counts.index[i], v + 1, str(v), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total classes: {len(class_counts)}\")\n",
    "print(f\"Total segments: {len(segments_df)}\")\n",
    "print(f\"Average segments per class: {len(segments_df) / len(class_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview files in segments_dir\n",
    "print(f\"Checking directory: {segments_dir}\")\n",
    "if os.path.exists(segments_dir):\n",
    "    files = os.listdir(segments_dir)\n",
    "    print(f\"Total files in segments_dir: {len(files)}\")\n",
    "    print(\"\\nFirst 10 files:\")\n",
    "    for file in files[:10]:\n",
    "        print(f\"  {file}\")\n",
    "    if len(files) > 10:\n",
    "        print(\"  ...\")\n",
    "else:\n",
    "    print(\"Directory does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e401f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading audio segments from disk...\")\n",
    "segments = load_audio_segments_from_disk(segments_csv_path, segments_dir, sr=32000)\n",
    "\n",
    "if not segments:\n",
    "    print(\"No segments loaded! Make sure AudioExtracting notebook has been run first.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(segments)} segments from disk\")\n",
    "    print(f\"First segment keys: {list(segments[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir(specs_dir)\n",
    "clean_dir(test_audios_dir)\n",
    "\n",
    "print(\"Creating spectrograms from loaded segments as .npy files...\")\n",
    "specs = create_spectrograms_from_segments_npy(\n",
    "    segments, specs_dir, output_csv, \n",
    "    test_audios_dir=test_audios_dir, \n",
    "    mels=224, hoplen=512, nfft=2048, \n",
    "    noise_reduce=False\n",
    ")\n",
    "\n",
    "print(\"Spectrogram generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221df6c",
   "metadata": {},
   "source": [
    "Aca veo los tama√±os de los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "amount = 20\n",
    "\n",
    "# List all .npy files in specs_dir\n",
    "spec_files = [f for f in os.listdir(specs_dir) if f.endswith('.npy')]\n",
    "\n",
    "# Fetch random .npy files\n",
    "random_files = random.sample(spec_files, min(amount, len(spec_files)))\n",
    "\n",
    "for fname in random_files:\n",
    "    spec_path = os.path.join(specs_dir, fname)\n",
    "    spec_array = np.load(spec_path)\n",
    "    print(f\"{fname}: {spec_array.shape}, dtype: {spec_array.dtype}, range: [{spec_array.min():.3f}, {spec_array.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SpecAugment on generated spectrograms (.npy format)\n",
    "from utils.specaugment import SpecAugment, get_recommended_params, visualize_specaugment, test_specaugment_on_random_spec\n",
    "\n",
    "num_specs = len(spec_files)\n",
    "print(f\"Total spectrograms available: {num_specs}\")\n",
    "\n",
    "num_classes = len(class_counts)\n",
    "print(f\"Total classes available: {num_classes}\")\n",
    "\n",
    "samples_per_class = num_specs / num_classes\n",
    "print(f\"Average samples per class: {samples_per_class:.1f}\")\n",
    "\n",
    "# Get recommended parameters for your dataset\n",
    "recommended_params = get_recommended_params(\n",
    "    num_samples=num_specs,\n",
    "    num_classes=num_classes,\n",
    "    input_size=(224, 313)  # height, width\n",
    ")\n",
    "\n",
    "print(\"Recommended SpecAugment parameters for your dataset:\")\n",
    "for key, value in recommended_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7510f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SpecAugment on a random spectrogram\n",
    "print(\"Testing SpecAugment on random spectrogram...\")\n",
    "test_specaugment_on_random_spec(shape=(224, 313), **recommended_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SpecAugment on actual generated spectrograms (.npy format)\n",
    "if len(specs) > 0:\n",
    "    print(f\"\\nTesting SpecAugment on actual spectrograms...\")\n",
    "    \n",
    "    # Load a few actual spectrograms for testing\n",
    "    test_files = [f for f in os.listdir(specs_dir) if f.endswith('.npy')][:3]\n",
    "    \n",
    "    for i, filename in enumerate(test_files):\n",
    "        print(f\"\\nTesting on {filename}\")\n",
    "        \n",
    "        # Load spectrogram from .npy file\n",
    "        spec_path = os.path.join(specs_dir, filename)\n",
    "        spec_array = np.load(spec_path)  # Already normalized to 0-1\n",
    "        spec_tensor = torch.tensor(spec_array, dtype=torch.float32)\n",
    "        \n",
    "        # Apply SpecAugment\n",
    "        augmenter = SpecAugment(**recommended_params)\n",
    "        augmented_spec = augmenter(spec_tensor)\n",
    "        \n",
    "        # Visualize\n",
    "        visualize_specaugment(\n",
    "            spec_tensor, \n",
    "            augmented_spec, \n",
    "            title=f\"SpecAugment Test - {filename}\"\n",
    "        )\n",
    "        \n",
    "        if i >= 2:  # Limit to 3 examples\n",
    "            break\n",
    "else:\n",
    "    print(\"No spectrograms available for testing. Run spectrogram generation first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
