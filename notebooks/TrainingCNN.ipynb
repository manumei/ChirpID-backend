{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078545a6",
   "metadata": {},
   "source": [
    "Here train the final model with cross validation and show the metrics. Once the final configuration and architecture is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a5894",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  CUDA not available - running on CPU (will be slow)\")\n",
    "\n",
    "# Performance optimization settings\n",
    "ENABLE_OPTIMIZATIONS = True  # Set to False to disable all optimizations\n",
    "ENABLE_PARALLEL_FOLDS = False  # Set to True for cross-validation mode\n",
    "MAX_PARALLEL_FOLDS = -1  # Adjust based on GPU memory\n",
    "\n",
    "def load_npy_data(specs_dir: str, specs_csv_path: str) -> Tuple[np.ndarray, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Load spectrograms from .npy files and metadata from CSV.\n",
    "    \n",
    "    Args:\n",
    "        specs_dir (str): Directory containing .npy spectrogram files\n",
    "        specs_csv_path (str): Path to CSV file containing metadata (filename, class_id, author)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.array, np.array]: Returns features, labels, and authors.\n",
    "        Features are already normalized to [0,1] and shaped as (N, 1, 224, 313)\n",
    "    \"\"\"\n",
    "    # Load metadata CSV\n",
    "    df = pd.read_csv(specs_csv_path)\n",
    "    \n",
    "    print(f\"Metadata shape: {df.shape}\")\n",
    "    print(f\"Number of classes: {df['class_id'].nunique()}\")\n",
    "    print(f\"Number of authors: {df['author'].nunique()}\")\n",
    "    \n",
    "    # Extract labels and authors\n",
    "    labels = df['class_id'].values.astype(np.int64)\n",
    "    authors = df['author'].values\n",
    "    filenames = df['filename'].values\n",
    "    \n",
    "    # Load spectrograms from .npy files\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        spec_path = os.path.join(specs_dir, filename)\n",
    "        \n",
    "        if os.path.exists(spec_path):\n",
    "            try:\n",
    "                # Load .npy file - already normalized to [0,1] as float32\n",
    "                spec_array = np.load(spec_path)\n",
    "                \n",
    "                # Add channel dimension: (1, height, width)\n",
    "                spec_array = spec_array[np.newaxis, ...]\n",
    "                \n",
    "                features_list.append(spec_array)\n",
    "                valid_indices.append(i)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {spec_path}\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features = np.array(features_list, dtype=np.float32)\n",
    "    \n",
    "    # Filter labels and authors to match loaded features\n",
    "    labels = labels[valid_indices]\n",
    "    authors = authors[valid_indices]\n",
    "    \n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Authors shape: {authors.shape}\")\n",
    "    print(f\"Unique classes: {len(np.unique(labels))}\")\n",
    "    print(f\"Unique authors: {len(np.unique(authors))}\")\n",
    "    print(f\"Successfully loaded {len(features)} out of {len(filenames)} spectrograms\")\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return features, labels, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New pipeline using .npy spectrograms from specs/ directory\n",
    "specs_dir = os.path.join('..', 'database', 'specs')\n",
    "specs_csv_path = os.path.join('..', 'database', 'meta', 'final_specs.csv')\n",
    "features, labels, authors = load_npy_data(specs_dir, specs_csv_path)\n",
    "\n",
    "# Display class distribution\n",
    "plt.figure(figsize=(9, 5))\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique_labels, counts, alpha=0.7)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xticks(unique_labels)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average samples per class: {len(labels) / len(unique_labels):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39958e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with a set seed\n",
    "from utils.split import get_set_seed_indices, get_set_seed_kfold_indices, display_split_statistics\n",
    "seed_single = 245323 # Quality: 0.2671\n",
    "seed_kfold = 11052 # Quality: 0.3332\n",
    "\n",
    "single_fold_split = get_set_seed_indices(\n",
    "    features=features,\n",
    "    labels=labels, \n",
    "    authors=authors,\n",
    "    test_size=0.2,\n",
    "    seed=seed_single)\n",
    "\n",
    "kfold_splits = get_set_seed_kfold_indices(\n",
    "    features=features,\n",
    "    labels=labels,\n",
    "    authors=authors,\n",
    "    n_splits=4,\n",
    "    seed=seed_kfold)\n",
    "\n",
    "display_split_statistics(single_fold_split, \"single\")\n",
    "display_split_statistics(kfold_splits, \"kfold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all models and training utilities\n",
    "from utils.final_models import (\n",
    "    BirdCNN_v5, BirdCNN_v5b, BirdCNN_v5c, BirdCNN_v5d, BirdCNN_v7, BirdCNN_v7b, BirdCNN_v7c, BirdCNN_v7d, BirdCNN_v7e\n",
    ")\n",
    "from utils.training_core import single_fold_training\n",
    "from utils.metrics import plot_metrics\n",
    "\n",
    "# Define Architectures\n",
    "model_architectures = {\n",
    "    'BirdCNN_v5': BirdCNN_v5,\n",
    "    'BirdCNN_v5c': BirdCNN_v5c,\n",
    "    'BirdCNN_v7': BirdCNN_v7,\n",
    "    'BirdCNN_v7e': BirdCNN_v7e,\n",
    "}\n",
    "\n",
    "# Define Configurations\n",
    "configurations = {\n",
    "    'configA': {\n",
    "            'name': 'Base',\n",
    "            'use_adam': True,\n",
    "            'estop_thresh': 37,\n",
    "            'batch_size': 45,\n",
    "            'use_class_weights': True,\n",
    "            'l2_regularization': 3.7e-4,\n",
    "            'lr_schedule': {'type': 'cosine', 'T_max': 73},\n",
    "            'initial_lr': 0.00137,\n",
    "            'standardize': False,\n",
    "            'spec_augment': True,\n",
    "            'noise_augment': False,\n",
    "            'num_epochs': 320,\n",
    "            'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "            'gradient_clipping': 0.73,\n",
    "            'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "            'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    \n",
    "    'configB': {\n",
    "            'name': 'Larger Batch Size',\n",
    "            'use_adam': True,\n",
    "            'estop_thresh': 45,\n",
    "            'batch_size': 56,\n",
    "            'use_class_weights': True,\n",
    "            'l2_regularization': 3.3e-4,\n",
    "            'lr_schedule': {'type': 'cosine', 'T_max': 65},\n",
    "            'initial_lr': 0.00149,\n",
    "            'standardize': False,\n",
    "            'spec_augment': True,\n",
    "            'noise_augment': False,\n",
    "            'num_epochs': 320,\n",
    "            'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "            'gradient_clipping': 0.65,\n",
    "            'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "            'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "    \n",
    "    'configC': {\n",
    "            'name': 'Lower Regularization',\n",
    "            'use_adam': True,\n",
    "            'estop_thresh': 45,\n",
    "            'batch_size': 42,\n",
    "            'use_class_weights': True,\n",
    "            'l2_regularization': 2.8e-4,\n",
    "            'lr_schedule': {'type': 'cosine', 'T_max': 78},\n",
    "            'initial_lr': 0.00121,\n",
    "            'standardize': False,\n",
    "            'spec_augment': True,\n",
    "            'noise_augment': False,\n",
    "            'num_epochs': 320,\n",
    "            'mixed_precision': ENABLE_OPTIMIZATIONS,\n",
    "            'gradient_clipping': 0.81,\n",
    "            'parallel_folds': ENABLE_PARALLEL_FOLDS,\n",
    "            'max_parallel_folds': MAX_PARALLEL_FOLDS\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize results database for all model-config combinations\n",
    "building_results = {}\n",
    "class_num = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70612d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b5a25e",
   "metadata": {},
   "source": [
    "## Show Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312bb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results plotting - Training metrics for all successful model-config combinations\n",
    "print(\"=\"*80)\n",
    "print(\"PLOTTING TRAINING METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Plot training metrics for all successful configurations\n",
    "successful_results = []\n",
    "for config_id, data in building_results.items():\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        try:\n",
    "            plot_metrics(config_id, result)\n",
    "            successful_results.append((config_id, result))\n",
    "            print(f\"✅ Plotted metrics for {config_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to plot {config_id}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully plotted metrics for {len(successful_results)} model-config combinations\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae844c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results table display - Comprehensive results for all model-config combinations\n",
    "print(\"=\"*80)\n",
    "print(\"BUILDING RESULTS TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive results table\n",
    "table_data = []\n",
    "for config_id, data in building_results.items():\n",
    "    if data['status'] == 'success' and 'result' in data:\n",
    "        result = data['result']\n",
    "        \n",
    "        # Parse model name and config\n",
    "        parts = config_id.split('_config')\n",
    "        model_name = parts[0]\n",
    "        config_name = 'config' + parts[1] if len(parts) > 1 else 'unknown'\n",
    "        \n",
    "        table_data.append({\n",
    "            'model': model_name,\n",
    "            'config': config_name,\n",
    "            'config_id': config_id,\n",
    "            'best_val_acc': result.get('best_val_acc', 0),\n",
    "            'best_val_f1': result.get('best_val_f1', 0),\n",
    "            'training_time': data.get('training_time', 0)\n",
    "        })\n",
    "\n",
    "# Create DataFrame and sort by best_val_f1 (descending)\n",
    "if table_data:\n",
    "    results_table = pd.DataFrame(table_data)\n",
    "    results_table = results_table.sort_values('best_val_f1', ascending=False)\n",
    "\n",
    "    print(\"MODEL BUILDING RESULTS TABLE (sorted by Best Val F1)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(results_table.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total successful runs: {len(results_table)}\")\n",
    "    print(f\"Best F1 score: {results_table['best_val_f1'].max():.4f} ({results_table.loc[results_table['best_val_f1'].idxmax(), 'config_id']})\")\n",
    "    print(f\"Best accuracy: {results_table['best_val_acc'].max():.4f} ({results_table.loc[results_table['best_val_acc'].idxmax(), 'config_id']})\")\n",
    "    print(f\"Average F1 score: {results_table['best_val_f1'].mean():.4f}\")\n",
    "    print(f\"Average accuracy: {results_table['best_val_acc'].mean():.4f}\")\n",
    "    print(f\"Total training time: {results_table['training_time'].sum()/3600:.2f} hours\")\n",
    "    \n",
    "    # Top 5 models by F1\n",
    "    print(f\"\\nTOP 5 MODELS BY F1 SCORE:\")\n",
    "    top_5 = results_table.head(5)[['model', 'config', 'best_val_f1', 'best_val_acc']]\n",
    "    print(top_5.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "else:\n",
    "    print(\"No successful results found to display.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885016a",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
