{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078545a6",
   "metadata": {},
   "source": [
    "Este agarra los datos del csv con la matriz de grayscale de cada espectrograma, y se los pasa al modelo de CNN de PyTorch (definido en aux file models.py), los guarda para poder llamarlo sin re-entrenar desde otros archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import util, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5744e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 5080\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae6d270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE ONE BEING USED\n",
    "\n",
    "# NOT NOISE-REDUCED\n",
    "# df = pd.read_csv(os.path.join('..', 'database', 'meta', 'final', 'train_data.csv'))\n",
    "\n",
    "# NOISE-REDUCED\n",
    "df = pd.read_csv(os.path.join('..', 'database', 'meta', 'final', 'train_data2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f9e4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels and pixel values\n",
    "labels = df['label'].values.astype(np.int64)\n",
    "features = df.drop(columns=['label']).values.astype(np.float32)\n",
    "features /= 255.0\n",
    "features = features.reshape(-1, 1, 313, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ea20568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (3070, 1, 313, 224)\n",
      "labels shape: (3070,)\n"
     ]
    }
   ],
   "source": [
    "print(\"features shape:\", features.shape)\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f430595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# 3. Create datasets and dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9406449f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.models' from 'c:\\\\Users\\\\manue\\\\Desktop\\\\manum\\\\coding\\\\ChirpID-backend\\\\utils\\\\models.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf451c3",
   "metadata": {},
   "source": [
    "Reset the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f4d1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model(lr=0.001, num_classes=28):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.BirdCNN(num_classes=num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return model, optimizer, criterion, device\n",
    "\n",
    "# Usage:\n",
    "model, optimizer, criterion, device = reset_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff7b142",
   "metadata": {},
   "source": [
    "Run to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dea2f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300/300: 100%|██████████| 300/300 [19:34<00:00,  3.91s/epoch, train_acc=0.969, train_loss=0.0931]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.BirdCNN(num_classes=28).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "pbar = tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "\n",
    "    val_losses.append(val_loss / val_total)\n",
    "    val_accuracies.append(val_correct / val_total)\n",
    "\n",
    "    pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    pbar.set_postfix(train_acc=f\"{train_acc:.3f}\", train_loss=f\"{train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Cross-Entropy Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(f\"Lowest Train Loss: {min(train_losses):.4f}\")\n",
    "print(f\"Lowest Val Loss:   {min(val_losses):.4f}\")\n",
    "print(f\"Highest Train Accuracy: {max(train_accuracies)*100:.2f}%\")\n",
    "print(f\"Highest Val Accuracy:   {max(val_accuracies)*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
